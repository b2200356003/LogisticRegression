{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEPifRWi8RB0"
      },
      "source": [
        "## BBM 409 - Programming Assignment 2\n",
        "\n",
        "* You can add as many cells as you want in-between each question.\n",
        "* Please add comments to your code to explain your work.  \n",
        "* Please add Markdown cells to answer the (non-coding) questions in the homework text. You can, however, refer to the outputs of code cells without adding them as images to the Markdown cell unless you are requested to do otherwise.\n",
        "* Please be careful about the order of runs of cells. Doing the homework, it is likely that you will be running the cells in different orders, however, they will be evaluated in the order they appear. Hence, please try running the cells in this order before submission to make sure they work.    \n",
        "* Please refer to the homework text for any implementation detail. Though you are somewhat expected to abide by the comments in the below cells, they are mainly just provided for guidance. That is, as long as you are not completely off this structure and your work pattern is understandable and traceable, it is fine. For instance, you do not have to implement a particular function within a cell just because the comment directs you to do so.\n",
        "* This document is also your report. Show your work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRABL12L8RB4"
      },
      "source": [
        "###  Insert personal information (name, surname, student id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7lsoAwDTHTQ"
      },
      "source": [
        "### DOĞUKAN AYTEKİN 2200356003"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb4QIkS68RB4"
      },
      "source": [
        "## 1. Weather Classification for Ankara"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq8IboH58RB4"
      },
      "source": [
        "### 1.1. Introduction\n",
        "* Brief overview of the classification task.\n",
        "* Description of the dataset used for experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0eQ_IKRKsaG"
      },
      "source": [
        "### Introduction answers\n",
        "* In multiclass classification task we have more classes than two to label the data points correctly.\n",
        "\n",
        "* This dataset is used to classify the weather condition of Ankara using some features.\n",
        "\n",
        "* Features : Tempmax, Tempmin, Temp , feelslikemax ,feelslikemin , feelslike , dew , humidity , precip , precipprob , precipcover , preciptype , snow , snowdepth , windgust , windspeed , winddir , sealevelpressure , cloudcover , visibility, solarradiation , solarenergy , uvindex , severerisk , moonphase\n",
        "\n",
        "* Label : weathercondition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-LA2-Ww8RB6"
      },
      "source": [
        "### 1.2. Data Loading and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CzXEXAD68RB6"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (c:\\Users\\dayte\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
            "File \u001b[1;32mc:\\Users\\dayte\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
            "File \u001b[1;32mc:\\Users\\dayte\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\dayte\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
            "File \u001b[1;32mc:\\Users\\dayte\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
            "File \u001b[1;32mc:\\Users\\dayte\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (c:\\Users\\dayte\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
          ]
        }
      ],
      "source": [
        "## Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from prettytable import PrettyTable\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from scipy.stats import chi2_contingency\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDRlIFmu8RB7"
      },
      "outputs": [],
      "source": [
        "## Read the regression data and transform it into a Numpy array collection.\n",
        "## (See pandas and numpy functions)\n",
        "\n",
        "dfW = pd.read_csv(\"ankara_weather_condition_dataset.csv\", sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sqsnzLB8RB7"
      },
      "outputs": [],
      "source": [
        "## Explore the dataset (e.g., size, features, target variables, summary statistics).\n",
        "## Check for any missing values and handle them if necessary.\n",
        "\n",
        "\n",
        "dfW.isnull().sum()\n",
        "\n",
        "# Handling categorical missing values, filling them with the most_frequent value in column\n",
        "impute_mode = SimpleImputer(strategy = 'most_frequent')\n",
        "impute_mode.fit(dfW[['preciptype']])\n",
        "\n",
        "dfW[['preciptype']] = impute_mode.transform(dfW[['preciptype']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt9Egoiumy17"
      },
      "outputs": [],
      "source": [
        "# one hot encode object type columns\n",
        "dfW = pd.get_dummies(dfW, columns=['preciptype'], prefix = 'P')\n",
        "\n",
        "dfW['weathercondition'] = dfW['weathercondition'].astype('category').cat.codes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLYWmiyQoXXs"
      },
      "outputs": [],
      "source": [
        "# Handling numerical missing values, filling them with mean\n",
        "dfW.isnull().sum()\n",
        "dfW = dfW.fillna(dfW.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl7NXrCvpd1S"
      },
      "outputs": [],
      "source": [
        "# changing boolean values to numerical values\n",
        "dfW = dfW.replace(True, 1)\n",
        "dfW = dfW.replace(False,0)\n",
        "\n",
        "# converting datatype of dataframe to float64 all\n",
        "for col in dfW.columns:\n",
        "    if dfW[col].dtype == 'int64' or dfW[col].dtype == 'int8' :\n",
        "        dfW[col] = dfW[col].astype('float64')\n",
        "\n",
        "# adding weathercondition column to end\n",
        "column_data = dfW.pop('weathercondition')\n",
        "dfW.insert(len(dfW.columns), 'weathercondition', column_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge1YGgKT8RB7"
      },
      "source": [
        "### 1.3. Data Preprocessing\n",
        "* Explain the preprocessing steps taken and their rationale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWZp8D39MlzC"
      },
      "source": [
        "* I apply chi square and correlation feature selection methods and for feature scaling standardization and normalization techniques are used.\n",
        "\n",
        "* In dataset we have imbalance in labels and I apply oversampling and undersampling methods to handle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ745n3N8RB7"
      },
      "outputs": [],
      "source": [
        "## Apply feature selection methods to see if it has a contribution on performance. (ablation study)\n",
        "## Implement functions for different feature scaling techniques to see their effects on the performance. (ablation study)\n",
        "## Explain the rationale your choice of methods.\n",
        "\n",
        "\n",
        "# This function creates different feature selected dataframes by the input\n",
        "#Feature selection with (correlation-> mode = 0) (chi-square -> mode = 1 )\n",
        "\n",
        "def FeatureSelection(dfW, mode):\n",
        "  drop_list = []\n",
        "  if (mode == 0):\n",
        "    index=0\n",
        "    drop_list = []\n",
        "    for i in dfW.corr()['weathercondition']:\n",
        "      if abs(i)< 0.3:\n",
        "        drop_list.append(dfW.columns[index])\n",
        "      index+=1\n",
        "\n",
        "  elif (mode==1):\n",
        "    for column in dfW.columns.tolist():\n",
        "      cross_tab = pd.crosstab(dfW['weathercondition'], dfW[column])\n",
        "      chi2, p_value, _, _ = chi2_contingency(cross_tab)\n",
        "      if(chi2 < 6000):\n",
        "        drop_list.append(column)\n",
        "\n",
        "  df2 = dfW.drop(drop_list, axis=1)\n",
        "  return df2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDdspZlvj-HK"
      },
      "outputs": [],
      "source": [
        "# Feature scaling methods\n",
        "\n",
        "# normalizing\n",
        "def normalize(arr):\n",
        "    min_val = np.min(arr)\n",
        "    max_val = np.max(arr)\n",
        "    normalized_arr = 2 * ((arr - min_val) / (max_val - min_val)) - 1\n",
        "    return normalized_arr\n",
        "\n",
        "# standardizing\n",
        "def standardize(matrix):\n",
        "    mean_vals = np.mean(matrix, axis=0)\n",
        "    std_vals = np.std(matrix, axis=0)\n",
        "    standardized_matrix = (matrix - mean_vals) / std_vals\n",
        "    return standardized_matrix\n",
        "\n",
        "# Creating a scaled matrix by the input\n",
        "# (ScaleNumber = -1 -> no scaling) , (ScaleNumber = 0 -> normalizing) , (ScaleNumber = 1 -> standardizing)\n",
        "\n",
        "def FeatureScaling(matrix,scaleNumber):\n",
        "    colMinusOne = matrix.shape[1]-1\n",
        "    if(scaleNumber!=-1):\n",
        "        for i in range(colMinusOne):\n",
        "            if (scaleNumber==0):\n",
        "                matrix[:,i]= normalize(matrix[:,i])\n",
        "            else:\n",
        "                matrix[:,i]= standardize(matrix[:,i])\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlTxWFCBm9Tg"
      },
      "outputs": [],
      "source": [
        "## Handle missing values (if any).\n",
        "## Split the dataset into training and testing sets.\n",
        "## Set the training set to be 80% and the test set to be 20% of the dataset.\n",
        "## Explain the rationale behind the chosen split ratio.\n",
        "\n",
        "# This function takes dataframe applies feature selection and scaling then splits feature and labels\n",
        "def ScaleAndSplit(df2,ScalingParameter,SelectionParameter):\n",
        "  df2 = FeatureSelection(dfW,SelectionParameter)\n",
        "  df2_matrix = df2.values\n",
        "  df2_matrix = FeatureScaling(df2_matrix,ScalingParameter)\n",
        "\n",
        "  label2 = df2_matrix[:,-1]\n",
        "  feature2 = df2_matrix[:,:df2.shape[1]-1]\n",
        "\n",
        "  return feature2, label2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC6Jxi4LC9sa"
      },
      "source": [
        "* Rationale behind the chosen split ratio : Splitting the training and test datasets into 80-20 ratio provides model to learns effiecently from training data and having enough data to objectively evaluate its generalization ability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM9re5sNBPHu"
      },
      "outputs": [],
      "source": [
        "# This function handles the imbalance of the label values with different techniques\n",
        "# mode=0 -> UnderSampling mode=1 -> OverSampling\n",
        "def HandleImbalance(X,Y,mode):\n",
        "  if mode==0:\n",
        "    rus = RandomUnderSampler(sampling_strategy='not minority')\n",
        "    X, Y = rus.fit_resample(X, Y)\n",
        "\n",
        "  elif mode==1:\n",
        "    smote = SMOTE(sampling_strategy='auto')\n",
        "    X, Y = smote.fit_resample(X, Y)\n",
        "\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFsC-NuPB5aE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This function takes the dataframe and apply Scale,Split,Handling Imbalances at the end it splits X,Y to train and test\n",
        "def DfToTrainAndSplit(df2,SamplingParameter,ScalingParameter,SelectionParameter):\n",
        "  # for scaling (-1 -> no scaling) , (0 -> normalizing) , (1 -> standardizing)\n",
        "  # for selection 0-> correlation 1-> chi-square selection\n",
        "  X,Y = ScaleAndSplit(df2,ScalingParameter,SelectionParameter)\n",
        "\n",
        "  # undersample->0 oversample->1\n",
        "  X,Y = HandleImbalance(X,Y,SamplingParameter)\n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "  return X_train,X_test,Y_train,Y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixG7dki9Bevd"
      },
      "outputs": [],
      "source": [
        "# sigmoid function to use in logistic regression\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# softmax function to use in logistic regression\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z)\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6yQkfFD8RB8"
      },
      "source": [
        "### 1.4. Logistic Regression Model\n",
        "* Implement logistic regression model.\n",
        "* Explain the reason behind the application of logistic regression on this type of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkFeF2LXNtou"
      },
      "source": [
        "* Logistic regression can be used for multiclass classification, and in this context, the softmax function is employed. The softmax function converts outputs into probabilities, enabling predictions among multiple classes. Given that there are more than two classes to classify in this dataset, it makes sense to use logistic regression.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Su0AkPcM8Ok"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g228aXZrHOs-"
      },
      "outputs": [],
      "source": [
        "# this function creates the y_pred\n",
        "def predict(X, weights, bias):\n",
        "    linear_model = np.dot(X, weights) + bias\n",
        "    predictions = softmax(linear_model)\n",
        "    return np.argmax(predictions, axis=1)\n",
        "\n",
        "# calculates accuracy\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    correct_predictions = np.sum(y_true == y_pred)\n",
        "    total_predictions = len(y_true)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYEoFWPJoZ-Y"
      },
      "outputs": [],
      "source": [
        "## Implement logistic regression model from scratch, using libraries like NumPy.\n",
        "\n",
        "def MulticlassLogisticRegression(X, y, learning_rate=0.01, num_iterations=1000, accuracy_track=False):\n",
        "\n",
        "    # add accuracy_list if plot the graph\n",
        "    accuracy_list = []\n",
        "\n",
        "    # taking necessary sizes\n",
        "    num_samples, num_features = X.shape\n",
        "    num_classes = len(np.unique(y))\n",
        "\n",
        "    #initalize the weight matrix not vector because it is multiclass classification\n",
        "    weights = np.zeros((num_features, num_classes))\n",
        "    bias = np.zeros((1, num_classes))\n",
        "\n",
        "    # One-hot-encode the labels\n",
        "    y_one_hot = np.eye(num_classes)[y.astype(int)]  # One-hot encoding\n",
        "\n",
        "\n",
        "    # iterate num_iterations times\n",
        "    for _ in range(num_iterations):\n",
        "\n",
        "      # calculate the score\n",
        "      score = np.dot(X, weights) + bias\n",
        "\n",
        "      # give score to softmax and take prediction probabilites\n",
        "      predictions = softmax(score)\n",
        "\n",
        "      #calculate gradients\n",
        "      dw = (1 / num_samples) * np.dot(X.T, (predictions - y_one_hot))\n",
        "      db = (1 / num_samples) * np.sum(predictions - y_one_hot, axis=0)\n",
        "\n",
        "      #change weight and bias via gradients\n",
        "      weights -= learning_rate * dw\n",
        "      bias -= learning_rate * db\n",
        "\n",
        "      if (accuracy_track):\n",
        "        y_pred = predict(X, weights, bias)\n",
        "        accuracy_list.append(accuracy_score(y,y_pred))\n",
        "\n",
        "    return weights, bias , accuracy_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G5n-KKRrg0b"
      },
      "outputs": [],
      "source": [
        "## Train the model using the training dataset.\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = DfToTrainAndSplit(dfW,SamplingParameter=0 ,ScalingParameter=1 ,SelectionParameter=0)\n",
        "weights, bias , accuracy_list = MulticlassLogisticRegression(X_train, Y_train, learning_rate=0.1, num_iterations=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le1Pd9Qg8RB8",
        "outputId": "aa38fe46-a1d6-4ddc-e615-85e67ec28207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy is :  0.9023569023569024\n"
          ]
        }
      ],
      "source": [
        "## Evaluate the model's performance on the training set by computing accuracy.\n",
        "\n",
        "y_pred = predict(X_train, weights, bias)\n",
        "print(\"Training accuracy is : \" , accuracy_score(Y_train,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23njcboArttc"
      },
      "source": [
        "### 1.5 Model Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z7dmNGprxDo",
        "outputId": "f6c8eb9e-53f0-4a6a-ac48-d04a7d4502c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy is :  0.9292929292929293\n"
          ]
        }
      ],
      "source": [
        "## Make predictions on the test set using the trained model.\n",
        "## Calculate accuracy for the test set.\n",
        "## Comment on the scores.\n",
        "\n",
        "y_pred = predict(X_test, weights, bias)\n",
        "print(\"Test accuracy is : \" , accuracy_score(Y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5SW0HwnN7uk"
      },
      "source": [
        "* I think for the scratch implementation in multiclass problem we have really good accuracy which is 0.94 . In the above cell we can see the accuracy difference of feature selection , scaling and handling imbalance techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8dFns1HJRBm"
      },
      "source": [
        "Because I create table in above cell it runs approximately in 1.5 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDG_al2zr76F",
        "outputId": "3582333f-5fb3-4b2c-8fe7-9d4b7dbfcdc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling and Scaling Methods Table\n",
            "+-----------------+------------------------+--------------------+\n",
            "| Sampling Method | Feature Scaling Method |      Accuracy      |\n",
            "+-----------------+------------------------+--------------------+\n",
            "|  Undersampling  |     Normalization      | 0.9057239057239057 |\n",
            "|   Oversampling  |     Normalization      | 0.908219923788786  |\n",
            "|  Undersampling  |    Standardization     | 0.9158249158249159 |\n",
            "|   Oversampling  |    Standardization     | 0.9367446924333152 |\n",
            "+-----------------+------------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "## Create a table to present the test accuracy for different feature scaling and selection methods.\n",
        "myTable = PrettyTable([\"Sampling Method\", \"Feature Scaling Method\",\"Accuracy\"])\n",
        "\n",
        "\n",
        "def CalculateAccuracy(df2,SamplingParameter,ScalingParameter,SelectionParameter):\n",
        "  X_train,X_test,Y_train,Y_test = DfToTrainAndSplit(df2,SamplingParameter,ScalingParameter,SelectionParameter)\n",
        "  weights, bias, accuracy_list = MulticlassLogisticRegression(X_train, Y_train, learning_rate=0.1, num_iterations=1000)\n",
        "  y_pred = predict(X_test, weights, bias)\n",
        "  accuracy = accuracy_score(Y_test,y_pred)\n",
        "  return accuracy\n",
        "\n",
        "myTable.add_row([\"Undersampling\", \"Normalization\" , CalculateAccuracy(dfW,0,0,1)])\n",
        "myTable.add_row([\"Oversampling\", \"Normalization\", CalculateAccuracy(dfW,1,0,1)])\n",
        "myTable.add_row([\"Undersampling\", \"Standardization\" , CalculateAccuracy(dfW,0,1,1)])\n",
        "myTable.add_row([\"Oversampling\", \"Standardization\", CalculateAccuracy(dfW,1,1,1)])\n",
        "\n",
        "print(\"Sampling and Scaling Methods Table\")\n",
        "print(myTable)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJVdIbG8PPOh"
      },
      "source": [
        "* As we can see from table the best sampling method to handle imbalance for this dataset is UnderSampling and best feature scaling method is standardization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugxH-gPvdA2t",
        "outputId": "55b02ea2-6fe0-46c2-eb76-9e075fcb8573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Selection Methods and Accuracy Table\n",
            "+--------------------------+--------------------+\n",
            "| Feature Selection Method |      Accuracy      |\n",
            "+--------------------------+--------------------+\n",
            "|       Correlation        | 0.903320631464344  |\n",
            "|     Chi-Square Test      | 0.9085465432770822 |\n",
            "+--------------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "## Create a table to present the test accuracy for different feature scaling and selection methods.\n",
        "\n",
        "# Table to see the difference between feature selection methods' effect on accuracy\n",
        "myTable = PrettyTable([\"Feature Selection Method\",\"Accuracy\"])\n",
        "\n",
        "myTable.add_row([\"Correlation\", CalculateAccuracy(dfW,1,0,0)])\n",
        "myTable.add_row([\"Chi-Square Test\", CalculateAccuracy(dfW,1,0,1)])\n",
        "\n",
        "print(\"Feature Selection Methods and Accuracy Table\")\n",
        "print(myTable)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc2dZImKPiYN"
      },
      "source": [
        "* We can see from table there is nearly no difference between feature selection methods in accuracy. Also we can change the threshold of them to get different results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aW87Td98RB9"
      },
      "source": [
        "### 1.6 Results Analysis and Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykMo02YtEslX"
      },
      "source": [
        "In the above cell I will train my model with training set then I will test them with test set in different learning rate and iteration parameters.\n",
        "\n",
        "Because I test with different parameters it will run around 1.5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjWiNuESH4ZA",
        "outputId": "8858065c-209d-438f-f7c7-faf3326b5193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+---------------+--------------------+\n",
            "| Number of Iterations | Learning Rate |      Accuracy      |\n",
            "+----------------------+---------------+--------------------+\n",
            "|         5000         |     0.001     | 0.835016835016835  |\n",
            "|         2000         |     0.001     | 0.8181818181818182 |\n",
            "|         1000         |     0.001     | 0.8148148148148148 |\n",
            "|         5000         |      0.01     | 0.9326599326599326 |\n",
            "|         2000         |      0.01     | 0.9124579124579124 |\n",
            "|         1000         |      0.01     | 0.8585858585858586 |\n",
            "|         5000         |      0.1      | 0.9494949494949495 |\n",
            "|         2000         |      0.1      | 0.9461279461279462 |\n",
            "|         1000         |      0.1      | 0.9292929292929293 |\n",
            "+----------------------+---------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# train the model with training dataset in different learning rates and iterations, calculate accuracy and append list to calculate the comparison table\n",
        "myTable_1 = PrettyTable([\"Number of Iterations\", \"Learning Rate\",\"Accuracy\"])\n",
        "\n",
        "learning_rate_list = [0.001,0.01,0.1]\n",
        "num_iterations = [5000,2000,1000]\n",
        "for learningRate in learning_rate_list:\n",
        "  for Iteration in num_iterations:\n",
        "    weights, bias, accuracy_list = MulticlassLogisticRegression(X_train, Y_train, learning_rate=learningRate, num_iterations=Iteration)\n",
        "    y_pred = predict(X_test, weights, bias)\n",
        "    accuracy = accuracy_score(Y_test,y_pred)\n",
        "    myTable_1.add_row([Iteration, learningRate, accuracy])\n",
        "\n",
        "print(myTable_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwvNqXfQQF6q"
      },
      "source": [
        "* We can see that number of iteration and learning rate hyperparameters can change accuracy very much. We have to choose number of iterations 5000 , learning rate 0.1 to get best result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Q3DK67Y8oyKr",
        "outputId": "142dc13f-38a6-42a3-a1af-32f67821f4fb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPPUlEQVR4nO3deVxU9f4/8NcMOyKL7CCCiru4oXJxL1FE5aqZqZmiXzMXLBUtl9xalDL1Ui5ZueYSlJpZGS64XZXEcMuNxCXcQAFhBBFw5vP7wx/nOjEq65yBeT0fj3k8nM98zpn3+XhzXvdzPucchRBCgIiIiMiIKOUugIiIiEjfGICIiIjI6DAAERERkdFhACIiIiKjwwBERERERocBiIiIiIwOAxAREREZHQYgIiIiMjoMQERERGR0GICIqpmRI0fCx8enTNvOnz8fCoWiYguq5q5fvw6FQoH169fLXQoRlQIDEJGeKBSKEr0OHjwod6myGDlyJGxsbOQuo0pKS0vDtGnT0LhxY1hbW6NGjRrw9/fHxx9/jKysLLnLIzJICj4LjEg/Nm3apPX+22+/xd69e7Fx40at9h49esDV1bXM31NYWAiNRgMLC4tSb/v48WM8fvwYlpaWZf7+sho5ciS2bt2KnJwcvX93eQghkJ+fDzMzM5iYmOj9+0+cOIHevXsjJycHb7zxBvz9/QEAf/zxB6Kjo9GhQwfs2bNH73URGTpTuQsgMhZvvPGG1vvff/8de/fuLdb+Tw8fPoS1tXWJv8fMzKxM9QGAqakpTE2N+5+F3Nxc1KhRo8T9FQqFLIERALKysjBgwACYmJjg1KlTaNy4sdbnCxYswDfffFMh31XacSEydDwFRmRAunXrhubNmyMxMRFdunSBtbU1Zs2aBQD46aef0KdPH3h4eMDCwgL169fHRx99BLVarbWPf64BKlqjsnjxYnz99deoX78+LCws0K5dO5w4cUJrW11rgBQKBSZOnIgdO3agefPmsLCwQLNmzRAbG1us/oMHD6Jt27awtLRE/fr18dVXX1X4uqLjx4+jV69esLOzg7W1Nbp27YqjR49q9fn7778xYcIENGrUCFZWVnB0dMSgQYNw/fp1rX7r16+HQqHAoUOHMGHCBLi4uKB27doA/vd3ceHCBbz00kuwtraGp6cnFi1apLUPXWuAik7n3bp1C/3794eNjQ2cnZ0xbdq0Yn9fGRkZGD58OGxtbWFvb4+wsDCcOXOmROuKvvrqK9y6dQtLly4tFn4AwNXVFbNnz5beKxQKzJ8/v1g/Hx8fjBw58oXjsnXrVqldVy0KhQLnzp2T2i5duoRXX30VtWrVgqWlJdq2bYudO3c+95iI9MW4/68ekQHKyMhASEgIhgwZgjfeeEM6HbZ+/XrY2NggIiICNjY22L9/P+bOnQuVSoXPPvvshfvdsmULHjx4gLFjx0KhUGDRokV45ZVXcPXq1RfOGh05cgTbt2/HhAkTULNmTXzxxRcYOHAgUlJS4OjoCAA4deoUevXqBXd3d3zwwQdQq9X48MMP4ezsXP5B+f/279+PkJAQ+Pv7Y968eVAqlVi3bh1efvll/Pe//0X79u0BPDktdOzYMQwZMgS1a9fG9evX8eWXX6Jbt264cOFCsRm1CRMmwNnZGXPnzkVubq7Ufv/+ffTq1QuvvPIKXnvtNWzduhXTp0+Hn58fQkJCnlurWq1GcHAwAgICsHjxYuzbtw9LlixB/fr1MX78eACARqNBaGgoEhISMH78eDRu3Bg//fQTwsLCSjQeO3fuhJWVFV599dXSDGOJ/XNc+vTpAxsbG3z//ffo2rWrVt+YmBg0a9YMzZs3BwCcP38eHTt2hKenJ2bMmIEaNWrg+++/R//+/bFt2zYMGDCgUmomKjFBRLIIDw8X//xPsGvXrgKAWLVqVbH+Dx8+LNY2duxYYW1tLR49eiS1hYWFCW9vb+n9tWvXBADh6OgoMjMzpfaffvpJABA///yz1DZv3rxiNQEQ5ubmIjk5WWo7c+aMACCWLVsmtYWGhgpra2tx69Ytqe3y5cvC1NS02D51CQsLEzVq1Hjm5xqNRjRo0EAEBwcLjUYjtT98+FDUrVtX9OjRQ6vtn+Lj4wUA8e2330pt69atEwBEp06dxOPHj7X6F/1dPN0/Pz9fuLm5iYEDB0ptReO7bt06rWMBID788EOtfbZu3Vr4+/tL77dt2yYAiKioKKlNrVaLl19+udg+dXFwcBAtW7Z8bp+nARDz5s0r1u7t7S3CwsKk988bl6FDhwoXFxet9jt37gilUql1vN27dxd+fn5a/9vUaDSiQ4cOokGDBiWumaiy8BQYkYGxsLDAqFGjirVbWVlJf37w4AHS09PRuXNnPHz4EJcuXXrhfgcPHgwHBwfpfefOnQEAV69efeG2QUFBqF+/vvS+RYsWsLW1lbZVq9XYt28f+vfvDw8PD6mfr6/vC2dKSur06dO4fPkyXn/9dWRkZCA9PR3p6enIzc1F9+7dcfjwYWg0GgDaY1VYWIiMjAz4+vrC3t4eJ0+eLLbvMWPG6FzAbGNjo7VGy9zcHO3bty/RmAHAuHHjtN537txZa9vY2FiYmZlhzJgxUptSqUR4eHiJ9q9SqVCzZs0S9S0LXeMyePBg3L17V+tqxa1bt0Kj0WDw4MEAgMzMTOzfvx+vvfaa9L/V9PR0ZGRkIDg4GJcvX8atW7cqrW6ikuApMCID4+npCXNz82Lt58+fx+zZs7F//36oVCqtz7Kzs1+43zp16mi9LwpD9+/fL/W2RdsXbXv37l3k5eXB19e3WD9dbWVx+fJlAHju6aHs7Gw4ODggLy8PkZGRWLduHW7dugXx1MWuusaqbt26OvdXu3btYuuXHBwccPbs2RfWa2lpWez039NjBjxZq+Tu7l7slFxJx8zW1hYPHjwoUd+y0DUuReuvYmJi0L17dwBPTn+1atUKDRs2BAAkJydDCIE5c+Zgzpw5Ovd99+5deHp6VlrtRC/CAERkYJ6evSiSlZWFrl27wtbWFh9++CHq168PS0tLnDx5EtOnT5dmPp7nWZdoixLcCaM821aUomP87LPP0KpVK519iu4j9Pbbb2PdunWYPHkyAgMDYWdnB4VCgSFDhugcK11jDlTOmFWkxo0b4/Tp0ygoKNAZmkvqnwuzi+gaFwsLC/Tv3x8//vgjVq5cibS0NBw9ehQLFy6U+hSN8bRp0xAcHKxz3xUVjInKigGIqAo4ePAgMjIysH37dnTp0kVqv3btmoxV/Y+LiwssLS2RnJxc7DNdbWVRdArO1tYWQUFBz+27detWhIWFYcmSJVLbo0ePDO6mgN7e3jhw4ECxWx2UdMxCQ0MRHx+Pbdu2YejQoS/s7+DgUGwMCgoKcOfOnVLVPXjwYGzYsAFxcXG4ePEihBDS6S8AqFevHoAnt2R40d8VkVy4BoioCiiaTXh65qGgoAArV66UqyQtJiYmCAoKwo4dO3D79m2pPTk5Gb/99luFfIe/vz/q16+PxYsX67xZ4r1797Tq+ecszbJly5450yGX4OBgFBYWat2rR6PRYMWKFSXafty4cXB3d8fUqVPx119/Ffv87t27+Pjjj6X39evXx+HDh7X6fP3116Uel6CgINSqVQsxMTGIiYlB+/bttU6Xubi4oFu3bvjqq690hqun/66I5MIZIKIqoEOHDnBwcEBYWBjeeecdKBQKbNy4Ua+noF5k/vz52LNnDzp27Ijx48dDrVZj+fLlaN68OU6fPl2ifRQWFmr9YBepVasWJkyYgNWrVyMkJATNmjXDqFGj4OnpiVu3buHAgQOwtbXFzz//DADo27cvNm7cCDs7OzRt2hTx8fHYt2+fdMm+oejfvz/at2+PqVOnIjk5GY0bN8bOnTuRmZkJAC+8f5KDgwN+/PFH9O7dG61atdK6E/TJkyfx3XffITAwUOr/5ptvYty4cRg4cCB69OiBM2fOYPfu3XBycipV3WZmZnjllVcQHR2N3NxcLF68uFifFStWoFOnTvDz88OYMWNQr149pKWlIT4+Hjdv3sSZM2dK9Z1EFY0BiKgKcHR0xC+//IKpU6di9uzZcHBwwBtvvIHu3bs/c42Fvvn7++O3337DtGnTMGfOHHh5eeHDDz/ExYsXS3SVGvBkVkvXotn69etjwoQJ6NatG+Lj4/HRRx9h+fLlyMnJgZubGwICAjB27Fip/+effw4TExNs3rwZjx49QseOHbFv3z6DGasiJiYm+PXXXzFp0iRs2LABSqUSAwYMwLx589CxY8cS3WE6ICAA586dw2effYZff/0VGzduhFKpRJMmTTBjxgxMnDhR6jtmzBhcu3YNa9asQWxsLDp37oy9e/dKi5lLY/DgwVi9ejUUCgVee+21Yp83bdoUf/zxBz744AOsX78eGRkZcHFxQevWrTF37txSfx9RReOzwIioUvXv3x/nz5+XruKiF9uxYwcGDBiAI0eOoGPHjnKXQ1QtcQ0QEVWYvLw8rfeXL1/Grl270K1bN3kKqgL+OWZqtRrLli2Dra0t2rRpI1NVRNUfT4ERUYWpV68eRo4ciXr16uHvv//Gl19+CXNzc7z33ntyl2aw3n77beTl5SEwMBD5+fnYvn07jh07hoULFz7z8nwiKj+eAiOiCjNq1CgcOHAAqampsLCwQGBgIBYuXMiZjOfYsmULlixZguTkZDx69Ai+vr4YP3681todIqp4DEBERERkdLgGiIiIiIwOAxAREREZHS6C1kGj0eD27duoWbPmC29ERkRERIZBCIEHDx7Aw8MDSuXz53gYgHS4ffs2vLy85C6DiIiIyuDGjRuoXbv2c/swAOlQs2ZNAE8G0NbWVuZqiIiIqCRUKhW8vLyk3/HnYQDSoei0l62tLQMQERFRFVOS5StcBE1ERERGhwGIiIiIjA4DEBERERkdBiAiIiIyOgxAREREZHQYgIiIiMjoMAARERGR0WEAIiIiIqPDAERERERGhwGIiIiIjA4DEBERERkdBiAiIiIyOnwYKhERERUjhMCdO3dQWFhYKfu3tbWFg4NDpey7JBiAiIiIjFBhYSHy8vKe+fmsWbOwYsWKSvv+mTNnYuHChZW2/xdhACIiIjIy169fh7+/PzIzM0vU39LSssJrMDWVN4IwABEREVVTubm56Ny5M86ePavVrlarS7R9jx49sHv3bigUisooT1YMQERERFXEjRs3EBISgrS0tBL1T09Pf+ZnSqUSsbGx6Ny58zP7WFhYVMvwAzAAERERlcuVK1fw+uuv4/79+zo/t7Gxwbp166BQKDBy5Ejk5OSU+bsuX75cpu3mz5+Pt956q1hdNWvWLHMtVR0DEBERUSlpNBqEh4fj5MmTSEhIeGH/Vq1aVej3L1++HC+99FKJ+lpbW8Pb27vazuSUFQMQERGRDiqVChMnTsTdu3eLfXb27FncuXNHq23JkiUICAjQaktKSsLo0aO12lavXo3GjRuXuS4nJyc0atSozNvTEwxARERklLZu3Ypt27Y98/Mff/wR+fn5z91HQEAAZs+eDU9PT7Ru3brY5x07dkRAQACuXbsGAKhbty6aNWtWvsKpQjAAERFRtZORkYFPP/30mettsrOzsWXLlhLtq1+/fhg4cGCxdisrK/Tt2/eFl4g3a9aMoccAMQAREVGlOn36NLZu3QohhN6+8/PPP0dubm6J+kZFRT1zfYyLiwsGDx7M9TPVEAMQERGViRACW7ZsKbYW5mmPHz/GzJkz9ViVth49eqBjx446PzMxMcHgwYPRoEEDPVdFhoABiIiISmTPnj24ceOG9P6nn37Czz//XOLtx44dWyl3FH6Wxo0bY+zYsZy9IZ0YgIiI6IWioqIwZcoUnZ9ZWlritddee+a2CoUCr7/+Onr27FlZ5RGVGgMQEVE1lZKSgitXrpR7P0lJSVrhJzQ0VPqzk5MT/vOf/8DOzq7c30OkTwxARETVxOPHj3Hx4kWo1Wrcvn0bffr0qfDvuH37Ntzd3St8v0T6xgBERFRFZGdnIysr65mfjx07Frt37y7W3rRp03J/t42NDb755huGH6o2GICIiAzYo0ePUFBQgDNnzuCll14q0VO8LS0t4eDgAGtra6xZswZdu3bVQ6VEVQsDEBGRgYqNjcW///1vFBYWarU/70qqIUOGYN26dZVdGlGVp5S7gBUrVsDHxweWlpYICAh47kPlCgsL8eGHH6J+/fqwtLREy5YtERsbW659EhEZmhs3bsDb2xshISFa4cfOzg5//vkn8vLynvli+CEqGVkDUExMDCIiIjBv3jycPHkSLVu2RHBwsM4HzwHA7Nmz8dVXX2HZsmW4cOECxo0bhwEDBuDUqVNl3icRkb5s3rwZHh4ecHZ2fu6rTp06SElJAQA4ODjg2rVryMvLQ0ZGBpo3by7zURBVDwqhz3uT/0NAQADatWuH5cuXAwA0Gg28vLzw9ttvY8aMGcX6e3h44P3330d4eLjUNnDgQFhZWWHTpk1l2qcuKpUKdnZ2yM7Ohq2tbXkPk4iMnBACEyZMwKpVq0q13caNG/Hqq6/q9eaBRFVZaX6/ZVsDVFBQgMTERK1bpCuVSgQFBSE+Pl7nNvn5+cX+IbCyssKRI0fKvM+i/T79xF+VSlWmYyIi4/Xbb79hwYIFxdbrAE/ux5Oamgrgyfqdo0ePvjDU2Nvbw8PDo1JqJSIZA1B6ejrUajVcXV212l1dXXHp0iWd2wQHB2Pp0qXo0qUL6tevj7i4OGzfvl26KqIs+wSAyMhIfPDBB+U8IiKqDv773/9i0aJFOoPMswghsGfPnhf2+9e//oVffvkFjo6O5SmRiCpAlboK7PPPP8eYMWPQuHFjKBQK1K9fH6NGjcLatWvLtd+ZM2ciIiJCeq9SqeDl5VXeconIAOXk5GDmzJlIT08v9pkQAjExMeXaf3R0NGrUqFGs3dzcHJ07d4aVlVW59k9EFUO2AOTk5AQTExOkpaVptaelpcHNzU3nNs7OztixYwcePXqEjIwMeHh4YMaMGahXr16Z9wkAFhYWsLCwKOcREZGh+/PPPxEUFFSiiyKWLVtW6sc7BAQEoGHDhmUtj4j0SLYAZG5uDn9/f8TFxaF///4AnixYjouLw8SJE5+7raWlJTw9PVFYWIht27ZJD+Erzz6JqHp69OgRli1bhvv37yMyMlJq79q1K1555RWd23Tq1Alt2rTRV4lEJANZT4FFREQgLCwMbdu2Rfv27REVFYXc3FyMGjUKADBixAh4enpK/2gdP34ct27dQqtWrXDr1i3Mnz8fGo0G7733Xon3SUTVV1JSEn755Rc8fXHr119/jcuXL2v1W7hwIaZPnw6lUvZboRGRTGQNQIMHD8a9e/cwd+5cpKamolWrVoiNjZUWMaekpGj9A/Xo0SPMnj0bV69ehY2NDXr37o2NGzfC3t6+xPskoupJrVajb9++SE5O1vl5o0aN0KtXLwQHByMkJETP1RGRoZH1PkCGivcBIjJ8J06cwI0bN6T3ly5dwvvvvw9bW1vpFHgRb29vzJ07F6amVeq6DyIqpSpxHyAiotJQqVQ4efIkhBA4fvy41v2+njZmzBgsXrxYz9URUVXDAEREJZKSkoLMzExZvlsIgb59++L27dvFPuvYsaP0Z0dHR7z77rv6LI2IqigGICKS5OXl6bxE/ODBgxg5cqT+C9LB19cX5ubmsLe3x8aNG6XbYBARlQYDEJGRKywsRF5eHu7fv482bdq8cJbH3d1dT5VpUyqVmDx5MqZNmybL9xNR9cIARGTEkpOT0b59e9y/f1+rXddzqtzd3XHgwAF4e3vrqzwiokrDAERUxWVlZaFjx45ISkoq9bZFz9ErYmZmhujo6GfeIJCIqLpgACKqQvLy8tC7d2+cO3dOatP1TKvSMDExwd69exEYGAgTExOYmZmVt0wiIoPHAERURSQmJqJ9+/bQaDQ6P1+8eDFef/31Uu/XxsYGNWvWLG95RERVCgMQURVw8+ZNtG3bVno/YcIEhIeHS+9tbGxQp04dOUojIqqSGICIDFBKSgqmTp2KBw8eAAB2794tffbDDz9g4MCBUCgUcpVHRFTlMQARGZjdu3ejV69eOj9btWoVXn31VT1XRERU/TAAERkIIQSWLFmidSfj8PBwBAQEAAC8vLzQrVs3maojIqpeGICI9EylUmHFihXIycnRaj927BgOHjwovd+5cydCQ0P1XB0RkXFgACKqRPn5+Vi/fr20lgcAlixZgtTU1Gdu4+DggAMHDqBly5b6KJGIyCgxABFVoIsXL+LYsWPS+2XLluHMmTM6+7Zr1w4dOnTQarOxscHUqVPh4OBQqXUSERk7BiCicrhy5YoUcHJychAWFqazn7e3N7p27Sq9b9KkCaZPn84ruYiIZMIARPQMt2/ffu7jJbKysp75yIi+fftK4cbX1xeLFi2CqSn/cyMiMhT8F5lIh6ysLPj5+b3wyehFOnbsCODJs7RmzpyJnj17VmZ5RERUTgxARDqsX78emZmZsLW1Re3atZ/Zz8LCAp988gkDDxFRFcMARPQPOTk5WLFiBQBg0aJFGDt2rMwVERFRRVPKXQCRIYmIiEDNmjWRnJwMOzs7DBs2TO6SiIioEnAGiIzesGHDEBMTA7VardU+Y8YM2NjYyFQVERFVJgYgqnY2bdqE9957D4WFhS/sm5mZCY1Go9X28ssv47fffoO5uXlllUhERDJjAKJq5fDhwxg+fHipt+vfvz9WrlwJhUIBV1dX3p+HiKiaYwCiKksIgalTp+Lo0aNSW0JCgvTnxMREWFpavnA/pqam8PX1hVLJJXFERMaCAYiqrCtXruA///mPzs/Onz+Ppk2b6rkiIiKqKhiAqMqKiIgAADRv3hyRkZFSe+PGjeHr6ytXWUREVAUwAFGVotFosHjxYsTHx+Pnn38GAISEhKBv374yV0ZERFUJAxAZNCEENmzYgKZNm2Lfvn3Yvn07EhMTpc9r1KiB2bNny1ghERFVRQxAZND27NmDUaNGFWt3d3fHxIkT8cYbb8DW1laGyoiIqCpjACKD9vRsDwC0a9cOISEheO+991CjRg2ZqiIioqqOAYgMUkFBAQ4cOID4+HipLTIyEtOnT+c9eoiIqNwYgMggLV26FDNnzpTer169GqNHj5axIiIiqk4YgMggxcXFAQAaNWqEZs2a4ZVXXpG5IiIiqk4YgMjg5OfnS3d0jo6ORqtWreQtiIiIqh3e+58Mzvr166FSqeDp6YnmzZvLXQ4REVVDnAEigzJ27Fh8/fXXAIBx48bB1JT/EyUioorHGSAyGNevX8fq1asBAM7Ozhg7dqzMFRERUXXFAESyOnv2LHx9feHs7Aw/Pz9oNBp07twZqampcHZ2lrs8IiKqpnh+gWS1YMECXLlyRatt9uzZUCqZzYmIqPIwAJHezZo1S7rMvehOz7t27YK3tzfs7e3h4eEhZ3lERGQEGIBIr+7cuYPIyEittu7duyMkJESmioiIyBgxAJFeFBYWYtasWTh58iQAwNfXF//5z3+gVCrRsWNHmasjIiJjwwBEevHzzz9j8eLF0vuePXuib9++MlZERETGjAGI9OL3338HAHTr1g1Dhw7FoEGDZK6IiIiMGQMQVbq7d+/is88+AwCMGDECo0aNkrkiIiIydrzWmCpVXl4eWrRoAQCwtLREv379ZK6IiIiIAYgq2ezZs5GWlgYA+PTTT1GrVi2ZKyIiImIAokqUk5MjPdri//7v//DOO+/IXBEREdETXANEFS49PR03b97Ezz//DJVKhQYNGuCbb76RuywiIiIJAxBVGLVajYSEBHTq1AkajUZqDw8P56MtiIjIoDAAUYXp3Lkz4uPjpffu7u7w9fXlVV9ERGRwZP+/5StWrICPjw8sLS0REBCAhISE5/aPiopCo0aNYGVlBS8vL0yZMgWPHj2SPp8/fz4UCoXWq3HjxpV9GEbv9u3bUvhxcnLC/v37cfv2bRw+fBi2trYyV0dERKRN1hmgmJgYREREYNWqVQgICEBUVBSCg4ORlJQEFxeXYv23bNmCGTNmYO3atejQoQP++usvjBw5EgqFAkuXLpX6NWvWDPv27ZPem5pyoquyHT9+HADg5+eHs2fPylwNERHR88k6A7R06VKMGTMGo0aNQtOmTbFq1SpYW1tj7dq1OvsfO3YMHTt2xOuvvw4fHx/07NkTQ4cOLTZrZGpqCjc3N+nl5OSkj8Mxat9++y0A4KWXXpK5EiIioheTLQAVFBQgMTERQUFB/ytGqURQUJDWOpKndejQAYmJiVLguXr1Knbt2oXevXtr9bt8+TI8PDxQr149DBs2DCkpKc+tJT8/HyqVSutFJff3339j586dAIBx48bJXA0REdGLyXZuKD09HWq1Gq6urlrtrq6uuHTpks5tXn/9daSnp6NTp04QQuDx48cYN24cZs2aJfUJCAjA+vXr0ahRI9y5cwcffPABOnfujHPnzqFmzZo69xsZGYkPPvig4g7OiOTl5aFNmzbQaDTo3r07mjRpIndJRERELyT7IujSOHjwIBYuXIiVK1fi5MmT2L59O3799Vd89NFHUp+QkBAMGjQILVq0QHBwMHbt2oWsrCx8//33z9zvzJkzkZ2dLb1u3Lihj8Op8opCT2ZmJgBgypQpMldERERUMrLNADk5OcHExER6TEKRtLQ0uLm56dxmzpw5GD58ON58800ATxbc5ubm4q233sL777+v814z9vb2aNiwIZKTk59Zi4WFBSwsLMpxNMZp79690unK0aNHo0+fPjJXREREVDKyzQCZm5vD398fcXFxUptGo0FcXBwCAwN1bvPw4cNiIcfExAQAIITQuU1OTg6uXLkCd3f3CqqciixfvhwA0LZtW3z99dcyV0NERFRysl4fHhERgbCwMLRt2xbt27dHVFQUcnNzpRvnjRgxAp6enoiMjAQAhIaGYunSpWjdujUCAgKQnJyMOXPmIDQ0VApC06ZNQ2hoKLy9vXH79m3MmzcPJiYmGDp0qGzHWR1dvXoVv/76K4AntyfgnZ6JiKgqkTUADR48GPfu3cPcuXORmpqKVq1aITY2VloYnZKSovXDOnv2bCgUCsyePRu3bt2Cs7MzQkNDsWDBAqnPzZs3MXToUGRkZMDZ2RmdOnXC77//DmdnZ70fX3WVlJSELl26QAiB4OBgNGjQQO6SiIiISkUhnnXuyIipVCrY2dkhOzubdzEG8PjxY/z4449QqVRQq9UYO3as9FlUVBQmTZokY3VERERPlOb3m7dIphf64osvMHXqVJ2ftW3bVs/VEBERlR8DED2XWq3GsmXLADy5EaWjoyOUSiXMzc3RvHlzdOjQQeYKiYiISo8BiJ4pPT0d27Ztw/Xr11GrVi3s27cPVlZWcpdFRERUbgxApNPff/+N+vXrQ61WA3hynx+GHyIiqi547TIVk5eXpxV+WrdujcmTJ8tbFBERUQXiDBAVEx0dLYWfffv2oXv37jJXREREVLE4A0RahBDSoudPPvmE4YeIiKolBiDS8tZbb+HUqVOwtLSUnrlGRERU3fAUGAEAHj16hJCQEBw8eBAAEBYWBkdHR3mLIiIiqiScASIAQFxcnBR+WrdujZUrV8pbEBERUSViACIAQEJCAgCgUaNGOHr0KB9uSkRE1Rp/5QjJycn48MMPAQBTpkzh/X6IiKjaYwAycvfv30eTJk0AAObm5njttddkroiIiKjyMQAZuZUrV+Lx48cAgPXr18PBwUHmioiIiCofA5CRi4+PBwD06tULQ4cOlbkaIiIi/WAAMmJCCGnx87x582SuhoiISH8YgIxYYmIi7t27BzMzM7Rq1UrucoiIiPSGAchICSEwYMAAAECLFi1gaWkpc0VERET6wwBkpI4ePYqbN28CAGbNmiVzNURERPrFAGSkPvroIwDA6NGj8corr8hcDRERkX4xABmhqKgo7NmzBwAwceJEmashIiLSPwYgI1QUftzc3Lj4mYiIjBIDkBFKTk4GAGzZskXmSoiIiOTBAGRk9u7di8uXLwMAGjRoIHM1RERE8mAAMjLz588HANSoUQMeHh7yFkNERCQTBiAjkpmZiWPHjgEAzp49C6WSf/1ERGSc+AtoJLKzs9G6dWsAQP369VGvXj2ZKyIiIpIPA5CR+Pzzz5GSkgIAeOmll2SuhoiISF4MQEbgzJkz0sNOBw0ahMWLF8tcERERkbwYgKq5X375RbrXj7OzMzZt2gQ7Ozt5iyIiIpIZA1A1dv36dfTr1096v2nTJpibm8tYERERkWFgAKrGvvzyS2g0GgBPZoJ69uwpc0VERESGgQGomsrLy8Pq1asBADt37kSfPn1kroiIiMhwMABVU9999x0yMzPh4+OD3r17y10OERGRQWEAqqbWrFkDAJgwYQJMTExkroaIiMiwMABVQ0IInD17FgAQGhoqczVERESGhwGoGrp79y5ycnKgVCpRt25ducshIiIyOAxA1VDR097r1KkDCwsLmashIiIyPAxA1dDp06cBAE2bNpW3ECIiIgNlKncBVHEKCgoQGhqKw4cPAwDat28vc0VERESGiQGoGtm2bRv27NkDAFAoFLz8nYiI6Bl4Cqwa2bVrFwBg4MCBuHPnDtq1aydzRURERIaJAagaOX78OADgzTffhKurq8zVEBERGS4GoGri0aNH0tVfbdq0kbkaIiIiw8YAVE3cvn0bAGBhYQFnZ2eZqyEiIjJsDEDVxK1btwAAtWvXhkKhkLkaIiIiw8YAVE3s3r0bAODp6SlzJURERIaPAaiaWLJkCQBw8TMREVEJlDoA+fj44MMPP0RKSkpl1ENlUFhYiPz8fADAxIkTZa6GiIjI8JU6AE2ePBnbt29HvXr10KNHD0RHR0s/viSPtLQ0CCFgZmaGTp06yV0OERGRwStTADp9+jQSEhLQpEkTvP3223B3d8fEiRNx8uTJyqiRXqBoAbS7uzuUSp7VJCIiepEy/1q2adMGX3zxBW7fvo158+Zh9erVaNeuHVq1aoW1a9dCCFGRddJzXL16FQDg4eEhcyVERERVQ5kDUGFhIb7//nv8+9//xtSpU9G2bVusXr0aAwcOxKxZszBs2LAS7WfFihXw8fGBpaUlAgICkJCQ8Nz+UVFRaNSoEaysrODl5YUpU6bg0aNH5dpnVfftt98CAE9/ERERlZQopcTERDFx4kTh6OgonJ2dxdSpU8XFixe1+vz555/C0tLyhfuKjo4W5ubmYu3ateL8+fNizJgxwt7eXqSlpensv3nzZmFhYSE2b94srl27Jnbv3i3c3d3FlClTyrxPXbKzswUAkZ2dXeJt5HLlyhUBQCgUCnHlyhW5yyEiIpJNaX6/Sx2AlEqlCA4OFt9//70oKCjQ2ScnJ0eMHDnyhftq3769CA8Pl96r1Wrh4eEhIiMjdfYPDw8XL7/8slZbRESE6NixY5n3qUtVCkCrV68WAESXLl3kLoWIiEhWpfn9LvUpsKtXryI2NhaDBg2CmZmZzj41atTAunXrnrufgoICJCYmIigoSGpTKpUICgpCfHy8zm06dOiAxMRE6ZTW1atXsWvXLvTu3bvM+6zqisYiMDBQ5kqIiIiqDtPSbnD37l2kpqYiICBAq/348eMwMTFB27ZtS7Sf9PR0qNXqYjfuc3V1xaVLl3Ru8/rrryM9PR2dOnWCEAKPHz/GuHHjMGvWrDLvEwDy8/O1LuVXqVQlOgZDUHRcLVu2lLkSIiKiqqPUM0Dh4eG4ceNGsfZbt24hPDy8Qop6loMHD2LhwoVYuXIlTp48ie3bt+PXX3/FRx99VK79RkZGws7OTnp5eXlVUMWV7+lngBEREVHJlHoG6MKFC2jTpk2x9tatW+PChQsl3o+TkxNMTEyQlpam1Z6WlgY3Nzed28yZMwfDhw/Hm2++CQDw8/NDbm4u3nrrLbz//vtl2icAzJw5ExEREdJ7lUpVJUKQEAI3b94EwGeAERERlUapZ4AsLCyKBQwAuHPnDkxNS56nzM3N4e/vj7i4OKlNo9EgLi7umetZHj58WOxGfyYmJgCehIGy7LPomGxtbbVeVUFmZqZ06o73ACIiIiq5Ugegnj17YubMmcjOzpbasrKyMGvWLPTo0aNU+4qIiMA333yDDRs24OLFixg/fjxyc3MxatQoAMCIESMwc+ZMqX9oaCi+/PJLREdH49q1a9i7dy/mzJmD0NBQKQi9aJ/VybFjxwA8uQO0paWlzNUQERFVHaU+BbZ48WJ06dIF3t7eaN26NQDg9OnTcHV1xcaNG0u1r8GDB+PevXuYO3cuUlNT0apVK8TGxkqLmFNSUrRmfGbPng2FQoHZs2fj1q1bcHZ2RmhoKBYsWFDifVYnK1asAIAS33SSiIiInlAIUfpnVuTm5mLz5s04c+YMrKys0KJFCwwdOvSZl8VXNSqVCnZ2dsjOzjbY02H37t2Di4sLAODKlSuoV6+ezBURERHJqzS/36WeAQKe3OfnrbfeKlNxVDGK7v/TuHFjhh8iIqJSKlMAAp5cDZaSkoKCggKt9n//+9/lLope7I8//gAAtGvXTuZKiIiIqp5SB6CrV69iwIAB+PPPP6FQKKSnvisUCgCAWq2u2ApJp7/++gsA0KxZM5krISIiqnpKfRXYpEmTULduXdy9exfW1tY4f/48Dh8+jLZt2+LgwYOVUCLpkpycDABo0KCBzJUQERFVPaWeAYqPj8f+/fvh5OQEpVIJpVKJTp06ITIyEu+88w5OnTpVGXXSU4QQuHz5MgDA19dX5mqIiIiqnlLPAKnVatSsWRPAk7s53759GwDg7e2NpKSkiq2OdPr7779x//59mJmZoWHDhnKXQ0REVOWUegaoefPmOHPmDOrWrYuAgAAsWrQI5ubm+Prrr3k1kp4UXQHWsmVL3gCRiIioDEodgGbPno3c3FwAwIcffoi+ffuic+fOcHR0RExMTIUXSMWlpKQAeHIJPBEREZVeqQNQcHCw9GdfX19cunQJmZmZcHBwkK4Eo8qVmZkJAHB0dJS5EiIioqqpVGuACgsLYWpqinPnzmm116pVi+FHjzIyMgA8GXciIiIqvVIFIDMzM9SpU4f3+pFZ0QwQAxAREVHZlPoqsPfffx+zZs2SfoRJ/xiAiIiIyqfUa4CWL1+O5ORkeHh4wNvbGzVq1ND6/OTJkxVWHOnGAERERFQ+pQ5A/fv3r4QyqKSEELh58yYAwNnZWeZqiIiIqiaFKHqYF0lUKhXs7OyQnZ0NW1tbucvRcv36ddStWxdmZmZQqVS8DxAREdH/V5rf71KvASJ5xcbGAgBatWrF8ENERFRGpT4FplQqn3vJO68Qq1xFN5scPHiwzJUQERFVXaUOQD/++KPW+8LCQpw6dQobNmzABx98UGGFkW63bt0CALRv317mSoiIiKquUgegfv36FWt79dVX0axZM8TExGD06NEVUhjpdvfuXQBcAE1ERFQeFbYG6F//+hfi4uIqanekQ0FBAbKzswEALi4uMldDRERUdVVIAMrLy8MXX3wBT0/PitgdPcO9e/cAACYmJrC3t5e3GCIioiqs1KfA/vnQUyEEHjx4AGtra2zatKlCiyNtT5/+Uip5AR8REVFZlToA/ec//9EKQEqlEs7OzggICICDg0OFFkfa7ty5AwBwc3OTuRIiIqKqrdQBaOTIkZVQBpVE0RVgPNVIRERUPqU+j7Ju3Tr88MMPxdp/+OEHbNiwoUKKIt2KHoHBAERERFQ+pQ5AkZGRcHJyKtbu4uKChQsXVkhRpBtngIiIiCpGqQNQSkoK6tatW6zd29sbKSkpFVIU6ZaUlAQAOsefiIiISq7UAcjFxQVnz54t1n7mzBk4OjpWSFFU3OPHj5GYmAgAaNeunczVEBERVW2lDkBDhw7FO++8gwMHDkCtVkOtVmP//v2YNGkShgwZUhk1EoBz584hLy8Ptra2aNiwodzlEBERVWmlvgrso48+wvXr19G9e3eYmj7ZXKPRYMSIEVwDVIkSEhIAPJn94T2AiIiIyqfUAcjc3BwxMTH4+OOPcfr0aVhZWcHPzw/e3t6VUR8BOHToEMaOHQsACAgIkLkaIiKiqk8hhBByF2FoVCoV7OzskJ2dDVtbW1lryc7ORu3atZGTkwMAuHDhApo0aSJrTURERIaoNL/fpT6XMnDgQHz66afF2hctWoRBgwaVdnf0Aj/++KMUfjZv3szwQ0REVAFKHYAOHz6M3r17F2sPCQnB4cOHK6Qo+p/ff/8dADB9+nS8/vrrMldDRERUPZQ6AOXk5MDc3LxYu5mZGVQqVYUURU8IIXDw4EEAvPSdiIioIpU6APn5+SEmJqZYe3R0NJo2bVohRdETJ06cQFJSEqytrdG9e3e5yyEiIqo2Sn0V2Jw5c/DKK6/gypUrePnllwEAcXFx2LJlC7Zu3VrhBRqzS5cuAQACAwNhb28vbzFERETVSKkDUGhoKHbs2IGFCxdi69atsLKyQsuWLbF//37UqlWrMmo0WkXP/qpdu7bMlRAREVUvpQ5AANCnTx/06dMHwJNLzr777jtMmzYNiYmJUKvVFVqgMePDT4mIiCpHmW8pfPjwYYSFhcHDwwNLlizByy+/LF2xRBXjxo0bABiAiIiIKlqpZoBSU1Oxfv16rFmzBiqVCq+99hry8/OxY8cOLoCuQBqNBqGhodi1axcAoEWLFjJXREREVL2UeAYoNDQUjRo1wtmzZxEVFYXbt29j2bJllVmb0bp8+bIUfgICAtCxY0eZKyIiIqpeSjwD9Ntvv+Gdd97B+PHj0aBBg8qsyeglJycDAKysrHDo0CEoFAqZKyIiIqpeSjwDdOTIETx48AD+/v4ICAjA8uXLkZ6eXpm1Ga2iANS7d29YWFjIXA0REVH1U+IA9K9//QvffPMN7ty5g7FjxyI6OhoeHh7QaDTYu3cvHjx4UJl1GpXz588DABo2bChzJURERNVTuZ4Gn5SUhDVr1mDjxo3IyspCjx49sHPnzoqsTxZyPg0+KysLDg4OAIDt27djwIABev1+IiKiqqpSnwb/tEaNGmHRokW4efMmvvvuu/Lsiv6/devWSX8OCAiQsRIiIqLqq1wBqIiJiQn69+9fLWZ/5Hbx4kUATx5+6uHhIXM1RERE1VOFBCCqOEULoN9++22ZKyEiIqq+GIAMTFEA8vX1lbkSIiKi6osByIDk5eVJj79gACIiIqo8DEAG5PLlywAAW1tbODk5yVwNERFR9cUAZEBGjBgB4MnsD+/+TEREVHkMIgCtWLECPj4+sLS0REBAABISEp7Zt1u3blAoFMVeffr0kfqMHDmy2Oe9evXSx6GUmVqtxpUrVwA8uQM0ERERVZ5SPQ2+MsTExCAiIgKrVq1CQEAAoqKiEBwcjKSkJLi4uBTrv337dhQUFEjvMzIy0LJlSwwaNEirX69evbTuqWPoj5S4dOkScnJyUKNGDcyfP1/ucoiIiKo12WeAli5dijFjxmDUqFFo2rQpVq1aBWtra6xdu1Zn/1q1asHNzU167d27F9bW1sUCkIWFhVa/orsrG6rjx48DANq2bQsTExOZqyEiIqreZA1ABQUFSExMRFBQkNSmVCoRFBSE+Pj4Eu1jzZo1GDJkCGrUqKHVfvDgQbi4uKBRo0YYP348MjIynrmP/Px8qFQqrZe+FQWg9u3b6/27iYiIjI2sASg9PR1qtRqurq5a7a6urkhNTX3h9gkJCTh37hzefPNNrfZevXrh22+/RVxcHD799FMcOnQIISEhUKvVOvcTGRkJOzs76eXl5VX2gyqDR48eYdu2bQCALl266PW7iYiIjJHsa4DKY82aNfDz8ys2azJkyBDpz35+fmjRogXq16+PgwcPonv37sX2M3PmTEREREjvVSqVXkNQTEwMMjIyUKdOHYNfrE1ERFQdyDoD5OTkBBMTE6SlpWm1p6Wlwc3N7bnb5ubmIjo6GqNHj37h99SrVw9OTk7SXZb/ycLCAra2tlovfSp6htqbb74JU9MqnUmJiIiqBFkDkLm5Ofz9/REXFye1aTQaxMXFITAw8Lnb/vDDD8jPz8cbb7zxwu+5efMmMjIy4O7uXu6aK0PRZf/dunWTtxAiIiIjIftVYBEREfjmm2+wYcMGXLx4EePHj0dubi5GjRoF4MnNAWfOnFlsuzVr1qB///5wdHTUas/JycG7776L33//HdevX0dcXBz69esHX19fBAcH6+WYSuPUqVO4efMmzMzM0KZNG7nLISIiMgqyn28ZPHgw7t27h7lz5yI1NRWtWrVCbGystDA6JSUFSqV2TktKSsKRI0ewZ8+eYvszMTHB2bNnsWHDBmRlZcHDwwM9e/bERx99ZJD3Alq+fDkA4NVXXy12JRsRERFVDoUQQshdhKFRqVSws7NDdnZ2pa0HEkLg888/x5QpUwAAR48eRYcOHSrlu4iIiIxBaX6/ZT8FZqy2bNkihZ/WrVu/cM0TERERVRwGIJls2rQJAGBnZ4c1a9bw4adERER6xAAkk6I7U2/atAmtW7eWuRoiIiLjwgAkk0ePHgEALC0tZa6EiIjI+DAAyYQBiIiISD4MQDLJz88HAIO8NJ+IiKi6YwCSCWeAiIiI5MMAJBMGICIiIvkwAMmEAYiIiEg+DEAyEEKgoKAAANcAERERyYEBSAZFC6ABzgARERHJgQFIBkWnvwAGICIiIjkwAMmgaAZIoVDAzMxM5mqIiIiMDwOQDIpmgCwsLPgMMCIiIhkwAMmAV4ARERHJiwFIBkWnwBiAiIiI5MEAJIOnT4ERERGR/jEAyaCwsBAAuACaiIhIJgxAMnj8+DEABiAiIiK5MADJoGgGyNTUVOZKiIiIjBMDkAyKZoAYgIiIiOTBACQDrgEiIiKSFwOQDDgDREREJC8GIBlwETQREZG8GIBkwEXQRERE8mIAkgFngIiIiOTFACQDzgARERHJiwFIBlwETUREJC8GIBnwFBgREZG8GIBkwFNgRERE8mIAkgFngIiIiOTFACQDzgARERHJiwFIBpwBIiIikhcDkAw4A0RERCQvBiAZ8DJ4IiIieTEAyYCnwIiIiOTFACQDngIjIiKSFwOQDDgDREREJC8GIBlwBoiIiEheDEAy4CJoIiIieTEAyYCnwIiIiOTFACQDngIjIiKSFwOQDDgDREREJC8GIBlwBoiIiEheDEAy4AwQERGRvBiAZMAZICIiInkxAMmAl8ETERHJiwFIBjwFRkREJC8GIBnwFBgREZG8GIBkwBkgIiIieTEAyYAzQERERPJiAJIBF0ETERHJyyAC0IoVK+Dj4wNLS0sEBAQgISHhmX27desGhUJR7NWnTx+pjxACc+fOhbu7O6ysrBAUFITLly/r41BKpGgGiKfAiIiI5CF7AIqJiUFERATmzZuHkydPomXLlggODsbdu3d19t++fTvu3Lkjvc6dOwcTExMMGjRI6rNo0SJ88cUXWLVqFY4fP44aNWogODgYjx490tdhPRdngIiIiOQlewBaunQpxowZg1GjRqFp06ZYtWoVrK2tsXbtWp39a9WqBTc3N+m1d+9eWFtbSwFICIGoqCjMnj0b/fr1Q4sWLfDtt9/i9u3b2LFjhx6P7Nm4CJqIiEhesgaggoICJCYmIigoSGpTKpUICgpCfHx8ifaxZs0aDBkyBDVq1AAAXLt2DampqVr7tLOzQ0BAwDP3mZ+fD5VKpfWqTFwETUREJC9ZA1B6ejrUajVcXV212l1dXZGamvrC7RMSEnDu3Dm8+eabUlvRdqXZZ2RkJOzs7KSXl5dXaQ+lVDgDREREJC/ZT4GVx5o1a+Dn54f27duXaz8zZ85Edna29Lpx40YFVagbZ4CIiIjkJWsAcnJygomJCdLS0rTa09LS4Obm9txtc3NzER0djdGjR2u1F21Xmn1aWFjA1tZW61WZuAiaiIhIXrIGIHNzc/j7+yMuLk5q02g0iIuLQ2Bg4HO3/eGHH5Cfn4833nhDq71u3bpwc3PT2qdKpcLx48dfuE994SkwIiIieck+BREREYGwsDC0bdsW7du3R1RUFHJzczFq1CgAwIgRI+Dp6YnIyEit7dasWYP+/fvD0dFRq12hUGDy5Mn4+OOP0aBBA9StWxdz5syBh4cH+vfvr6/Dei6eAiMiIpKX7L/AgwcPxr179zB37lykpqaiVatWiI2NlRYxp6SkQKnUnqhKSkrCkSNHsGfPHp37fO+995Cbm4u33noLWVlZ6NSpE2JjY2FpaVnpx1MSnAEiIiKSl0IIIeQuwtCoVCrY2dkhOzu7wtcDaTQamJiYAADu3bsHJyenCt0/ERGRsSrN73eVvgqsKiqa/QE4A0RERCQXBiA9K1r/A3ANEBERkVwYgPTs6RkgBiAiIiJ5MADpGU+BERERyY8BSM+KToEpFIpiV7cRERGRfvAXWM94F2giIiL5MQDpWUFBAYAnd8EmIiIieTAA6VlRALKwsJC5EiIiIuPFAKRn+fn5ADgDREREJCcGID3jKTAiIiL5MQDpGU+BERERyY8BSM94CoyIiEh+DEB6xlNgRERE8mMA0rOiGSCeAiMiIpIPA5CecQaIiIhIfgxAesZF0ERERPJjANIzLoImIiKSHwOQnvEUGBERkfwYgPSMp8CIiIjkxwCkZzwFRkREJD8GID3jKTAiIiL5MQDpGe8DREREJD8GID3jDBAREZH8GID0jIugiYiI5McApGdcBE1ERCQ/BiA94ykwIiIi+TEA6RlPgREREcmPAUjPeAqMiIhIfgxAesZTYERERPJjANIzngIjIiKSHwOQnvEUGBERkfwYgPSMp8CIiIjkxwCkZ3wUBhERkfwYgPSMM0BERETyYwDSMy6CJiIikh8DkJ5xETQREZH8GID0jKfAiIiI5McApGc8BUZERCQ/BiA94ykwIiIi+TEA6RlPgREREcmPAUjPeB8gIiIi+TEA6ZFGo8Hjx48BcAaIiIhITgxAelQ0+wNwBoiIiEhODEB6lJeXJ/3ZyspKxkqIiIiMGwOQHhUFIBMTE5iZmclcDRERkfFiANKjogDE2R8iIiJ5MQDpEQMQERGRYWAA0iMGICIiIsPAAKRHDEBERESGgQFIjxiAiIiIDAMDkB4xABERERkGBiA9YgAiIiIyDAxAesQAREREZBhkD0ArVqyAj48PLC0tERAQgISEhOf2z8rKQnh4ONzd3WFhYYGGDRti165d0ufz58+HQqHQejVu3LiyD6NEGICIiIgMg6mcXx4TE4OIiAisWrUKAQEBiIqKQnBwMJKSkuDi4lKsf0FBAXr06AEXFxds3boVnp6e+Pvvv2Fvb6/Vr1mzZti3b5/03tRU1sOUMAAREREZBlmTwdKlSzFmzBiMGjUKALBq1Sr8+uuvWLt2LWbMmFGs/9q1a5GZmYljx45Jj5Lw8fEp1s/U1BRubm6VWntZWVlZoUaNGnKXQUREZNRkOwVWUFCAxMREBAUF/a8YpRJBQUGIj4/Xuc3OnTsRGBiI8PBwuLq6onnz5li4cCHUarVWv8uXL8PDwwP16tXDsGHDkJKS8txa8vPzoVKptF6V4d1338XDhw/x5ZdfVsr+iYiIqGRkC0Dp6elQq9VwdXXVand1dUVqaqrOba5evYqtW7dCrVZj165dmDNnDpYsWYKPP/5Y6hMQEID169cjNjYWX375Ja5du4bOnTvjwYMHz6wlMjISdnZ20svLy6tiDpKIiIgMkmEsjikhjUYDFxcXfP311zAxMYG/vz9u3bqFzz77DPPmzQMAhISESP1btGiBgIAAeHt74/vvv8fo0aN17nfmzJmIiIiQ3qtUKoYgIiKiaky2AOTk5AQTExOkpaVptaelpT1z/Y67uzvMzMxgYmIitTVp0gSpqakoKCiAubl5sW3s7e3RsGFDJCcnP7MWCwsLWFhYlPFIiIiIqKqR7RSYubk5/P39ERcXJ7VpNBrExcUhMDBQ5zYdO3ZEcnIyNBqN1PbXX3/B3d1dZ/gBgJycHFy5cgXu7u4VewBERERUZcl6H6CIiAh888032LBhAy5evIjx48cjNzdXuipsxIgRmDlzptR//PjxyMzMxKRJk/DXX3/h119/xcKFCxEeHi71mTZtGg4dOoTr16/j2LFjGDBgAExMTDB06FC9Hx8REREZJlnXAA0ePBj37t3D3LlzkZqailatWiE2NlZaGJ2SkgKl8n8ZzcvLC7t378aUKVPQokULeHp6YtKkSZg+fbrU5+bNmxg6dCgyMjLg7OyMTp064ffff4ezs7Pej4+IiIgMk0IIIeQuwtCoVCrY2dkhOzsbtra2cpdDREREJVCa32/ZH4VBREREpG8MQERERGR0GICIiIjI6DAAERERkdFhACIiIiKjwwBERERERocBiIiIiIxOlXoYqr4U3RpJpVLJXAkRERGVVNHvdkluccgApMODBw8AgE+EJyIiqoIePHgAOzu75/bhnaB10Gg0uH37NmrWrAmFQlGh+1apVPDy8sKNGzd4l+lKxHHWD46zfnCc9YdjrR+VNc5CCDx48AAeHh5aj9LShTNAOiiVStSuXbtSv8PW1pb/cekBx1k/OM76wXHWH461flTGOL9o5qcIF0ETERGR0WEAIiIiIqPDAKRnFhYWmDdvHiwsLOQupVrjOOsHx1k/OM76w7HWD0MYZy6CJiIiIqPDGSAiIiIyOgxAREREZHQYgIiIiMjoMAARERGR0WEA0qMVK1bAx8cHlpaWCAgIQEJCgtwlVSmRkZFo164datasCRcXF/Tv3x9JSUlafR49eoTw8HA4OjrCxsYGAwcORFpamlaflJQU9OnTB9bW1nBxccG7776Lx48f6/NQqpRPPvkECoUCkydPlto4zhXj1q1beOONN+Do6AgrKyv4+fnhjz/+kD4XQmDu3Llwd3eHlZUVgoKCcPnyZa19ZGZmYtiwYbC1tYW9vT1Gjx6NnJwcfR+KwVKr1ZgzZw7q1q0LKysr1K9fHx999JHWs6I4zmVz+PBhhIaGwsPDAwqFAjt27ND6vKLG9ezZs+jcuTMsLS3h5eWFRYsWVcwBCNKL6OhoYW5uLtauXSvOnz8vxowZI+zt7UVaWprcpVUZwcHBYt26deLcuXPi9OnTonfv3qJOnToiJydH6jNu3Djh5eUl4uLixB9//CH+9a9/iQ4dOkifP378WDRv3lwEBQWJU6dOiV27dgknJycxc+ZMOQ7J4CUkJAgfHx/RokULMWnSJKmd41x+mZmZwtvbW4wcOVIcP35cXL16VezevVskJydLfT755BNhZ2cnduzYIc6cOSP+/e9/i7p164q8vDypT69evUTLli3F77//Lv773/8KX19fMXToUDkOySAtWLBAODo6il9++UVcu3ZN/PDDD8LGxkZ8/vnnUh+Oc9ns2rVLvP/++2L79u0CgPjxxx+1Pq+Icc3Ozhaurq5i2LBh4ty5c+K7774TVlZW4quvvip3/QxAetK+fXsRHh4uvVer1cLDw0NERkbKWFXVdvfuXQFAHDp0SAghRFZWljAzMxM//PCD1OfixYsCgIiPjxdCPPkPVqlUitTUVKnPl19+KWxtbUV+fr5+D8DAPXjwQDRo0EDs3btXdO3aVQpAHOeKMX36dNGpU6dnfq7RaISbm5v47LPPpLasrCxhYWEhvvvuOyGEEBcuXBAAxIkTJ6Q+v/32m1AoFOLWrVuVV3wV0qdPH/F///d/Wm2vvPKKGDZsmBCC41xR/hmAKmpcV65cKRwcHLT+3Zg+fbpo1KhRuWvmKTA9KCgoQGJiIoKCgqQ2pVKJoKAgxMfHy1hZ1ZadnQ0AqFWrFgAgMTERhYWFWuPcuHFj1KlTRxrn+Ph4+Pn5wdXVVeoTHBwMlUqF8+fP67F6wxceHo4+ffpojSfAca4oO3fuRNu2bTFo0CC4uLigdevW+Oabb6TPr127htTUVK1xtrOzQ0BAgNY429vbo23btlKfoKAgKJVKHD9+XH8HY8A6dOiAuLg4/PXXXwCAM2fO4MiRIwgJCQHAca4sFTWu8fHx6NKlC8zNzaU+wcHBSEpKwv3798tVIx+Gqgfp6elQq9VaPwYA4OrqikuXLslUVdWm0WgwefJkdOzYEc2bNwcApKamwtzcHPb29lp9XV1dkZqaKvXR9fdQ9Bk9ER0djZMnT+LEiRPFPuM4V4yrV6/iyy+/REREBGbNmoUTJ07gnXfegbm5OcLCwqRx0jWOT4+zi4uL1uempqaoVasWx/n/mzFjBlQqFRo3bgwTExOo1WosWLAAw4YNAwCOcyWpqHFNTU1F3bp1i+2j6DMHB4cy18gARFVSeHg4zp07hyNHjshdSrVz48YNTJo0CXv37oWlpaXc5VRbGo0Gbdu2xcKFCwEArVu3xrlz57Bq1SqEhYXJXF318f3332Pz5s3YsmULmjVrhtOnT2Py5Mnw8PDgOBs5ngLTAycnJ5iYmBS7SiYtLQ1ubm4yVVV1TZw4Eb/88gsOHDiA2rVrS+1ubm4oKChAVlaWVv+nx9nNzU3n30PRZ/TkFNfdu3fRpk0bmJqawtTUFIcOHcIXX3wBU1NTuLq6cpwrgLu7O5o2barV1qRJE6SkpAD43zg9798NNzc33L17V+vzx48fIzMzk+P8/7377ruYMWMGhgwZAj8/PwwfPhxTpkxBZGQkAI5zZamoca3Mf0sYgPTA3Nwc/v7+iIuLk9o0Gg3i4uIQGBgoY2VVixACEydOxI8//oj9+/cXmxb19/eHmZmZ1jgnJSUhJSVFGufAwED8+eefWv/R7d27F7a2tsV+jIxV9+7d8eeff+L06dPSq23bthg2bJj0Z45z+XXs2LHYbRz++usveHt7AwDq1q0LNzc3rXFWqVQ4fvy41jhnZWUhMTFR6rN//35oNBoEBATo4SgM38OHD6FUav/UmZiYQKPRAOA4V5aKGtfAwEAcPnwYhYWFUp+9e/eiUaNG5Tr9BYCXwetLdHS0sLCwEOvXrxcXLlwQb731lrC3t9e6Soaeb/z48cLOzk4cPHhQ3LlzR3o9fPhQ6jNu3DhRp04dsX//fvHHH3+IwMBAERgYKH1edHl2z549xenTp0VsbKxwdnbm5dkv8PRVYEJwnCtCQkKCMDU1FQsWLBCXL18WmzdvFtbW1mLTpk1Sn08++UTY29uLn376SZw9e1b069dP52XErVu3FsePHxdHjhwRDRo0MPrLs58WFhYmPD09pcvgt2/fLpycnMR7770n9eE4l82DBw/EqVOnxKlTpwQAsXTpUnHq1Cnx999/CyEqZlyzsrKEq6urGD58uDh37pyIjo4W1tbWvAy+qlm2bJmoU6eOMDc3F+3btxe///673CVVKQB0vtatWyf1ycvLExMmTBAODg7C2tpaDBgwQNy5c0drP9evXxchISHCyspKODk5ialTp4rCwkI9H03V8s8AxHGuGD///LNo3ry5sLCwEI0bNxZff/211ucajUbMmTNHuLq6CgsLC9G9e3eRlJSk1ScjI0MMHTpU2NjYCFtbWzFq1Cjx4MEDfR6GQVOpVGLSpEmiTp06wtLSUtSrV0+8//77WpdVc5zL5sCBAzr/TQ4LCxNCVNy4njlzRnTq1ElYWFgIT09P8cknn1RI/QohnrodJhEREZER4BogIiIiMjoMQERERGR0GICIiIjI6DAAERERkdFhACIiIiKjwwBERERERocBiIiIiIwOAxARkQ4+Pj6IioqSuwwiqiQMQEQku5EjR6J///4AgG7dumHy5Ml6++7169fD3t6+WPuJEyfw1ltv6a0OItIvU7kLICKqDAUFBTA3Ny/z9s7OzhVYDREZGs4AEZHBGDlyJA4dOoTPP/8cCoUCCoUC169fBwCcO3cOISEhsLGxgaurK4YPH4709HRp227dumHixImYPHkynJycEBwcDABYunQp/Pz8UKNGDXh5eWHChAnIyckBABw8eBCjRo1Cdna29H3z588HUPwUWEpKCvr16wcbGxvY2tritddeQ1pamvT5/Pnz0apVK2zcuBE+Pj6ws7PDkCFD8ODBg8odNCIqEwYgIjIYn3/+OQIDAzFmzBjcuXMHd+7cgZeXF7KysvDyyy+jdevW+OOPPxAbG4u0tDS89tprWttv2LAB5ubmOHr0KFatWgUAUCqV+OKLL3D+/Hls2LAB+/fvx3vvvQcA6NChA6KiomBrayt937Rp04rVpdFo0K9fP2RmZuLQoUPYu3cvrl69isGDB2v1u3LlCnbs2IFffvkFv/zyCw4dOoRPPvmkkkaLiMqDp8CIyGDY2dnB3Nwc1tbWcHNzk9qXL1+O1q1bY+HChVLb2rVr4eXlhb/++gsNGzYEADRo0ACLFi3S2ufT64l8fHzw8ccfY9y4cVi5ciXMzc1hZ2cHhUKh9X3/FBcXhz///BPXrl2Dl5cXAODbb79Fs2bNcOLECbRr1w7Ak6C0fv161KxZEwAwfPhwxMXFYcGCBeUbGCKqcJwBIiKDd+bMGRw4cAA2NjbSq3HjxgCezLoU8ff3L7btvn370L17d3h6eqJmzZoYPnw4MjIy8PDhwxJ//8WLF+Hl5SWFHwBo2rQp7O3tcfHiRanNx8dHCj8A4O7ujrt375bqWIlIPzgDREQGLycnB6Ghofj000+Lfebu7i79uUaNGlqfXb9+HX379sX48eOxYMEC1KpVC0eOHMHo0aNRUFAAa2vrCq3TzMxM671CoYBGo6nQ7yCiisEAREQGxdzcHGq1WqutTZs22LZtG3x8fGBqWvJ/thITE6HRaLBkyRIolU8mvL///vsXft8/NWnSBDdu3MCNGzekWaALFy4gKysLTZs2LXE9RGQ4eAqMiAyKj48Pjh8/juvXryM9PR0ajQbh4eHIzMzE0KFDceLECVy5cgW7d+/GqFGjnhtefH19UVhYiGXLluHq1avYuHGjtDj66e/LyclBXFwc0tPTdZ4aCwoKgp+fH4YNG4aTJ08iISEBI0aMQNeuXdG2bdsKHwMiqnwMQERkUKZNmwYTExM0bdoUzs7OSElJgYeHB44ePQq1Wo2ePXvCz88PkydPhr29vTSzo0vLli2xdOlSfPrpp2jevDk2b96MyMhIrT4dOnTAuHHjMHjwYDg7OxdbRA08OZX1008/wcHBAV26dEFQUBDq1auHmJiYCj9+ItIPhRBCyF0EERERkT5xBoiIiIiMDgMQERERGR0GICIiIjI6DEBERERkdBiAiIiIyOgwABEREZHRYQAiIiIio8MAREREREaHAYiIiIiMDgMQERERGR0GICIiIjI6DEBERERkdP4f7UeKjv7UvoUAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Plot training accuracys to visualize the learning curve.\n",
        "## Interpret the results of the ablation study on feature scaling and selection.\n",
        "## Discuss the impact of feature scaling on model performance.\n",
        "## Summarize key findings from the logistic regression analysis.\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = DfToTrainAndSplit(dfW,SamplingParameter=0 ,ScalingParameter=1 ,SelectionParameter=0)\n",
        "weights, bias , accuracy_list = MulticlassLogisticRegression(X_train, Y_train, learning_rate=0.1, num_iterations=1000,accuracy_track=True)\n",
        "\n",
        "index_list = []\n",
        "for i in range(len(accuracy_list)):\n",
        "    index_list.append(i)\n",
        "\n",
        "plt.title(\"Training Learning Curve\")\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(index_list,accuracy_list, color=\"black\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGtX341uCb9e"
      },
      "source": [
        "* To summarize:\n",
        "  For this type of dataset logistic regression works best when we choose number of iterations 5000 , learning rate 0.1 . Accuracy is really good for a scratch implementation. I think for this dataset it runs faster for multiple classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXYTfefHQerX"
      },
      "source": [
        "* If we look at the graph in some points we have very little decrease in accuracy it can be because of learning rate is 0.1 . If we choose it smaller this decreases won't be there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfa8FPbS8RCC"
      },
      "source": [
        "## 2. DDoS Attack Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70saVqfas_xw"
      },
      "source": [
        "### 2.1. Introduction\n",
        "* Brief overview of the classification task.\n",
        "* Description of the dataset used for classification analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdLjLw3GQ_hZ"
      },
      "source": [
        "### Introduction answers\n",
        "* In this classification task we are trying to predict the ddos attack from conditions that comes from features.\n",
        "\n",
        "* For this task we have binary classification problem differs than first one.\n",
        "\n",
        "* For this task we have bigger task it has nearly 100000 samples.\n",
        "\n",
        "* Features : dt, switch, src, dst, pktcount, bytecount, dur,dur_nsec, tot_dur, flows, packetins, pktperflow, byteperflow, pktrate, Pairflow, Protocol,port_no,\n",
        " tx_bytes, rx_bytes, tx_kbps, rx_kbps, tot_kbps\n",
        "\n",
        " Label : label (if label equals one it is ddos attack if equals zero it is not)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y4hOS8Js_xw"
      },
      "source": [
        "### 2.2. Data Loading and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y92cEVTIs_xw"
      },
      "outputs": [],
      "source": [
        "## Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from prettytable import PrettyTable\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from scipy.stats import chi2_contingency\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "grKg2iiAs_xw",
        "outputId": "8d4310f2-7a77-4f3f-cd97-7152ba7d89f6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2f4ef44a-dafd-4990-a40a-e7b113fd769b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dt</th>\n",
              "      <th>switch</th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>pktcount</th>\n",
              "      <th>bytecount</th>\n",
              "      <th>dur</th>\n",
              "      <th>dur_nsec</th>\n",
              "      <th>tot_dur</th>\n",
              "      <th>flows</th>\n",
              "      <th>...</th>\n",
              "      <th>pktrate</th>\n",
              "      <th>Pairflow</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>port_no</th>\n",
              "      <th>tx_bytes</th>\n",
              "      <th>rx_bytes</th>\n",
              "      <th>tx_kbps</th>\n",
              "      <th>rx_kbps</th>\n",
              "      <th>tot_kbps</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11425</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.1</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>45304</td>\n",
              "      <td>48294064</td>\n",
              "      <td>100</td>\n",
              "      <td>716000000</td>\n",
              "      <td>1.010000e+11</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>3</td>\n",
              "      <td>143928631</td>\n",
              "      <td>3917</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11605</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.1</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>126395</td>\n",
              "      <td>134737070</td>\n",
              "      <td>280</td>\n",
              "      <td>734000000</td>\n",
              "      <td>2.810000e+11</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>4</td>\n",
              "      <td>3842</td>\n",
              "      <td>3520</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11425</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.2</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>90333</td>\n",
              "      <td>96294978</td>\n",
              "      <td>200</td>\n",
              "      <td>744000000</td>\n",
              "      <td>2.010000e+11</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>1</td>\n",
              "      <td>3795</td>\n",
              "      <td>1242</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11425</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.2</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>90333</td>\n",
              "      <td>96294978</td>\n",
              "      <td>200</td>\n",
              "      <td>744000000</td>\n",
              "      <td>2.010000e+11</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>2</td>\n",
              "      <td>3688</td>\n",
              "      <td>1492</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11425</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.2</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>90333</td>\n",
              "      <td>96294978</td>\n",
              "      <td>200</td>\n",
              "      <td>744000000</td>\n",
              "      <td>2.010000e+11</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>3</td>\n",
              "      <td>3413</td>\n",
              "      <td>3665</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103434</th>\n",
              "      <td>5262</td>\n",
              "      <td>3</td>\n",
              "      <td>10.0.0.5</td>\n",
              "      <td>10.0.0.7</td>\n",
              "      <td>79</td>\n",
              "      <td>7742</td>\n",
              "      <td>81</td>\n",
              "      <td>842000000</td>\n",
              "      <td>8.184200e+10</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ICMP</td>\n",
              "      <td>1</td>\n",
              "      <td>15209</td>\n",
              "      <td>12720</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103435</th>\n",
              "      <td>5262</td>\n",
              "      <td>3</td>\n",
              "      <td>10.0.0.5</td>\n",
              "      <td>10.0.0.7</td>\n",
              "      <td>79</td>\n",
              "      <td>7742</td>\n",
              "      <td>81</td>\n",
              "      <td>842000000</td>\n",
              "      <td>8.184200e+10</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ICMP</td>\n",
              "      <td>3</td>\n",
              "      <td>15099</td>\n",
              "      <td>14693</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103436</th>\n",
              "      <td>5262</td>\n",
              "      <td>3</td>\n",
              "      <td>10.0.0.11</td>\n",
              "      <td>10.0.0.5</td>\n",
              "      <td>31</td>\n",
              "      <td>3038</td>\n",
              "      <td>31</td>\n",
              "      <td>805000000</td>\n",
              "      <td>3.180500e+10</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ICMP</td>\n",
              "      <td>2</td>\n",
              "      <td>3409</td>\n",
              "      <td>3731</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103437</th>\n",
              "      <td>5262</td>\n",
              "      <td>3</td>\n",
              "      <td>10.0.0.11</td>\n",
              "      <td>10.0.0.5</td>\n",
              "      <td>31</td>\n",
              "      <td>3038</td>\n",
              "      <td>31</td>\n",
              "      <td>805000000</td>\n",
              "      <td>3.180500e+10</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ICMP</td>\n",
              "      <td>1</td>\n",
              "      <td>15209</td>\n",
              "      <td>12720</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103438</th>\n",
              "      <td>5262</td>\n",
              "      <td>3</td>\n",
              "      <td>10.0.0.11</td>\n",
              "      <td>10.0.0.5</td>\n",
              "      <td>31</td>\n",
              "      <td>3038</td>\n",
              "      <td>31</td>\n",
              "      <td>805000000</td>\n",
              "      <td>3.180500e+10</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ICMP</td>\n",
              "      <td>3</td>\n",
              "      <td>15099</td>\n",
              "      <td>14693</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103439 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f4ef44a-dafd-4990-a40a-e7b113fd769b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f4ef44a-dafd-4990-a40a-e7b113fd769b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f4ef44a-dafd-4990-a40a-e7b113fd769b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec6cb547-a198-472a-8d39-0efe310515c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec6cb547-a198-472a-8d39-0efe310515c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec6cb547-a198-472a-8d39-0efe310515c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_738b1482-759d-4c76-a26e-1969e000eaa8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_738b1482-759d-4c76-a26e-1969e000eaa8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           dt  switch        src       dst  pktcount  bytecount  dur  \\\n",
              "0       11425       1   10.0.0.1  10.0.0.8     45304   48294064  100   \n",
              "1       11605       1   10.0.0.1  10.0.0.8    126395  134737070  280   \n",
              "2       11425       1   10.0.0.2  10.0.0.8     90333   96294978  200   \n",
              "3       11425       1   10.0.0.2  10.0.0.8     90333   96294978  200   \n",
              "4       11425       1   10.0.0.2  10.0.0.8     90333   96294978  200   \n",
              "...       ...     ...        ...       ...       ...        ...  ...   \n",
              "103434   5262       3   10.0.0.5  10.0.0.7        79       7742   81   \n",
              "103435   5262       3   10.0.0.5  10.0.0.7        79       7742   81   \n",
              "103436   5262       3  10.0.0.11  10.0.0.5        31       3038   31   \n",
              "103437   5262       3  10.0.0.11  10.0.0.5        31       3038   31   \n",
              "103438   5262       3  10.0.0.11  10.0.0.5        31       3038   31   \n",
              "\n",
              "         dur_nsec       tot_dur  flows  ...  pktrate  Pairflow  Protocol  \\\n",
              "0       716000000  1.010000e+11      3  ...      451         0       UDP   \n",
              "1       734000000  2.810000e+11      2  ...      451         0       UDP   \n",
              "2       744000000  2.010000e+11      3  ...      451         0       UDP   \n",
              "3       744000000  2.010000e+11      3  ...      451         0       UDP   \n",
              "4       744000000  2.010000e+11      3  ...      451         0       UDP   \n",
              "...           ...           ...    ...  ...      ...       ...       ...   \n",
              "103434  842000000  8.184200e+10      5  ...        0         0      ICMP   \n",
              "103435  842000000  8.184200e+10      5  ...        0         0      ICMP   \n",
              "103436  805000000  3.180500e+10      5  ...        1         0      ICMP   \n",
              "103437  805000000  3.180500e+10      5  ...        1         0      ICMP   \n",
              "103438  805000000  3.180500e+10      5  ...        1         0      ICMP   \n",
              "\n",
              "        port_no   tx_bytes rx_bytes  tx_kbps  rx_kbps  tot_kbps  label  \n",
              "0             3  143928631     3917        0      0.0       0.0      0  \n",
              "1             4       3842     3520        0      0.0       0.0      0  \n",
              "2             1       3795     1242        0      0.0       0.0      0  \n",
              "3             2       3688     1492        0      0.0       0.0      0  \n",
              "4             3       3413     3665        0      0.0       0.0      0  \n",
              "...         ...        ...      ...      ...      ...       ...    ...  \n",
              "103434        1      15209    12720        1      1.0       2.0      0  \n",
              "103435        3      15099    14693        1      1.0       2.0      0  \n",
              "103436        2       3409     3731        0      0.0       0.0      0  \n",
              "103437        1      15209    12720        1      1.0       2.0      0  \n",
              "103438        3      15099    14693        1      1.0       2.0      0  \n",
              "\n",
              "[103439 rows x 23 columns]"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Read the classification data and transform it into a Numpy array collection.\n",
        "## (See pandas and numpy functions)\n",
        "df = pd.read_csv(\"ddos_dataset.csv\")\n",
        "data_matrix = df.values\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7IeqyCNs_xw",
        "outputId": "caf120cc-98bc-4010-bee6-9e7858722672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 103439 entries, 0 to 103438\n",
            "Data columns (total 23 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   dt           103439 non-null  int64  \n",
            " 1   switch       103439 non-null  int64  \n",
            " 2   src          103439 non-null  object \n",
            " 3   dst          103439 non-null  object \n",
            " 4   pktcount     103439 non-null  int64  \n",
            " 5   bytecount    103439 non-null  int64  \n",
            " 6   dur          103439 non-null  int64  \n",
            " 7   dur_nsec     103439 non-null  int64  \n",
            " 8   tot_dur      103439 non-null  float64\n",
            " 9   flows        103439 non-null  int64  \n",
            " 10  packetins    103439 non-null  int64  \n",
            " 11  pktperflow   103439 non-null  int64  \n",
            " 12  byteperflow  103439 non-null  int64  \n",
            " 13  pktrate      103439 non-null  int64  \n",
            " 14  Pairflow     103439 non-null  int64  \n",
            " 15  Protocol     103439 non-null  object \n",
            " 16  port_no      103439 non-null  int64  \n",
            " 17  tx_bytes     103439 non-null  int64  \n",
            " 18  rx_bytes     103439 non-null  int64  \n",
            " 19  tx_kbps      103439 non-null  int64  \n",
            " 20  rx_kbps      103439 non-null  float64\n",
            " 21  tot_kbps     103439 non-null  float64\n",
            " 22  label        103439 non-null  int64  \n",
            "dtypes: float64(3), int64(17), object(3)\n",
            "memory usage: 18.2+ MB\n"
          ]
        }
      ],
      "source": [
        "## Explore the dataset (e.g., size, features, target variables, summary statistics).\n",
        "## Check for any missing values and handle them if necessary.\n",
        "\n",
        "# not any NaN values\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqA4aCvXs_xx"
      },
      "source": [
        "### 2.3. Data Preprocessing\n",
        "* Explain the preprocessing steps taken and their rationale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cReL8n39RSNz"
      },
      "source": [
        "* For this binary classification task I apply same different methods with multiclass one to compare the accuracy results.\n",
        "\n",
        "* I apply chi square and correlation feature selection methods and for feature scaling standardization and normalization techniques are used.\n",
        "\n",
        "* In dataset we have imbalance in labels and I apply oversampling and undersampling methods to handle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JveBkEv6fnAg"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df, columns=['Protocol'], prefix = 'P')\n",
        "df  = df.drop(['src' , 'dst'] , axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJGtQmyr34sE",
        "outputId": "02eca027-018d-4cf8-9a29-df94f52faf45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 103439 entries, 0 to 103438\n",
            "Data columns (total 23 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   dt           103439 non-null  int64  \n",
            " 1   switch       103439 non-null  int64  \n",
            " 2   pktcount     103439 non-null  int64  \n",
            " 3   bytecount    103439 non-null  int64  \n",
            " 4   dur          103439 non-null  int64  \n",
            " 5   dur_nsec     103439 non-null  int64  \n",
            " 6   tot_dur      103439 non-null  float64\n",
            " 7   flows        103439 non-null  int64  \n",
            " 8   packetins    103439 non-null  int64  \n",
            " 9   pktperflow   103439 non-null  int64  \n",
            " 10  byteperflow  103439 non-null  int64  \n",
            " 11  pktrate      103439 non-null  int64  \n",
            " 12  Pairflow     103439 non-null  int64  \n",
            " 13  port_no      103439 non-null  int64  \n",
            " 14  tx_bytes     103439 non-null  int64  \n",
            " 15  rx_bytes     103439 non-null  int64  \n",
            " 16  tx_kbps      103439 non-null  int64  \n",
            " 17  rx_kbps      103439 non-null  float64\n",
            " 18  tot_kbps     103439 non-null  float64\n",
            " 19  label        103439 non-null  int64  \n",
            " 20  P_ICMP       103439 non-null  bool   \n",
            " 21  P_TCP        103439 non-null  bool   \n",
            " 22  P_UDP        103439 non-null  bool   \n",
            "dtypes: bool(3), float64(3), int64(17)\n",
            "memory usage: 16.1 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()\n",
        "df = df.astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4ZVX7gO4Lb8"
      },
      "outputs": [],
      "source": [
        "# change boolean values to numerical values\n",
        "df = df.replace(True, 1)\n",
        "df = df.replace(False,0)\n",
        "\n",
        "# make label the last column\n",
        "column_data = df.pop('label')\n",
        "df.insert(len(df.columns), 'label', column_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3O6CJvl2zV0"
      },
      "outputs": [],
      "source": [
        "# Feature scaling methods\n",
        "\n",
        "# normalizing\n",
        "def normalize(arr):\n",
        "    min_val = np.min(arr)\n",
        "    max_val = np.max(arr)\n",
        "    normalized_arr = 2 * ((arr - min_val) / (max_val - min_val)) - 1\n",
        "    return normalized_arr\n",
        "\n",
        "# standardizing\n",
        "def standardize(matrix):\n",
        "    mean_vals = np.mean(matrix, axis=0)\n",
        "    std_vals = np.std(matrix, axis=0)\n",
        "    standardized_matrix = (matrix - mean_vals) / std_vals\n",
        "    return standardized_matrix\n",
        "\n",
        "# Creating a scaled matrix by the input\n",
        "# (ScaleNumber = -1 -> no scaling) , (ScaleNumber = 0 -> normalizing) , (ScaleNumber = 1 -> standardizing)\n",
        "\n",
        "def FeatureScaling(matrix,scaleNumber):\n",
        "    colMinusOne = matrix.shape[1]-1\n",
        "    if(scaleNumber!=-1):\n",
        "        for i in range(colMinusOne):\n",
        "            if (scaleNumber==0):\n",
        "                matrix[:,i]= normalize(matrix[:,i])\n",
        "            else:\n",
        "                matrix[:,i]= standardize(matrix[:,i])\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHb4s1le29nq"
      },
      "outputs": [],
      "source": [
        "# This function handles the imbalance of the label values with different techniques\n",
        "# mode=0 -> UnderSampling mode=1 -> OverSampling\n",
        "def HandleImbalance(X,Y,mode):\n",
        "  if mode==0:\n",
        "    rus = RandomUnderSampler(sampling_strategy='not minority')\n",
        "    X, Y = rus.fit_resample(X, Y)\n",
        "\n",
        "  elif mode==1:\n",
        "    smote = SMOTE(sampling_strategy='auto')\n",
        "    X, Y = smote.fit_resample(X, Y)\n",
        "\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rhWOgjSoZRh"
      },
      "outputs": [],
      "source": [
        "# apply feature selection\n",
        "def FeatureSelection(df, mode):\n",
        "  drop_list = []\n",
        "  if (mode == 0):\n",
        "    index=0\n",
        "    drop_list = []\n",
        "    for i in df.corr()['label']:\n",
        "      if abs(i)< 0.2:\n",
        "        drop_list.append(df.columns[index])\n",
        "      index+=1\n",
        "\n",
        "  elif (mode==1):\n",
        "    for column in df.columns.tolist():\n",
        "      cross_tab = pd.crosstab(df['label'], df[column])\n",
        "      chi2, p_value, _, _ = chi2_contingency(cross_tab)\n",
        "      if(chi2 < 6000):\n",
        "        drop_list.append(column)\n",
        "\n",
        "  df2 = df.drop(drop_list, axis=1)\n",
        "\n",
        "  return df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsGnw_XGqAfy"
      },
      "outputs": [],
      "source": [
        "# apply feature selection and scaling methods take feature and label matrixes\n",
        "def ScaleAndSplit(df2,ScalingParameter,SelectionParameter):\n",
        "  df2 = FeatureSelection(df,SelectionParameter)\n",
        "  df2_matrix = df2.values\n",
        "  df2_matrix = FeatureScaling(df2_matrix,ScalingParameter)\n",
        "\n",
        "  label2 = df2_matrix[:,-1]\n",
        "  feature2 = df2_matrix[:,:df2.shape[1]-1]\n",
        "\n",
        "  return feature2, label2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em7YW65Qqr4f"
      },
      "outputs": [],
      "source": [
        "# This function takes the dataframe and apply Scale,Split,Handling Imbalances at the end it splits X,Y to train and test\n",
        "\n",
        "def DfToTrainAndSplit(df2,SamplingParameter,ScalingParameter,SelectionParameter):\n",
        "  # for scaling (-1 -> no scaling) , (0 -> normalizing) , (1 -> standardizing)\n",
        "  # for selection 0-> correlation 1-> chi-square selection\n",
        "  X,Y = ScaleAndSplit(df2,ScalingParameter,SelectionParameter)\n",
        "\n",
        "  # undersample->0 oversample->1\n",
        "  X,Y = HandleImbalance(X,Y,SamplingParameter)\n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "  X_train = X_train.T\n",
        "  Y_train = Y_train.reshape(1, X_train.shape[1])\n",
        "\n",
        "  X_test = X_test.T\n",
        "  Y_test = Y_test.reshape(1, X_test.shape[1])\n",
        "\n",
        "  return X_train,X_test,Y_train,Y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSGP9Tjps_xx"
      },
      "outputs": [],
      "source": [
        "## Handle missing values (if any).\n",
        "## Split the dataset into training and testing sets. (80% train, 20% test)\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = DfToTrainAndSplit(df,0,1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRS54_rhDPh_"
      },
      "source": [
        "* Rationale behind the chosen split ratio : Splitting the training and test datasets into 80-20 ratio provides model to learns effiecently from training data and having enough data to objectively evaluate its generalization ability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbq_d141nduZ"
      },
      "source": [
        "### 2.4. Logistic Regression Model\n",
        "* Implement logistic regression model.\n",
        "* Explain the reason behind the application of logistic regression on this type of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu_yyiKi3IpE"
      },
      "outputs": [],
      "source": [
        "# sigmoid function to use in logistic regression\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "566AXiEFoANg"
      },
      "outputs": [],
      "source": [
        "## Implement logistic regression model from scratch, using libraries like NumPy.\n",
        "\n",
        "def BinaryLogisticRegression(X,Y , LearningRate , iteration, accuracy_track = False):\n",
        "    accuracy_list = []\n",
        "    m = np.shape(X)[1]\n",
        "    number_of_weights = np.shape(X)[0]\n",
        "    weights = np.zeros((number_of_weights,1))\n",
        "    Bias = 0\n",
        "\n",
        "    for i in range(iteration):\n",
        "        score = np.dot(weights.T,X) + Bias\n",
        "        prob = sigmoid(score)\n",
        "\n",
        "        dW = (1/m) * np.dot(prob-Y, X.T)\n",
        "        dB = (1/m) * np.sum(prob - Y)\n",
        "\n",
        "        weights = weights - LearningRate * dW.T\n",
        "        Bias = Bias - LearningRate * dB\n",
        "\n",
        "        if (accuracy_track):\n",
        "          score_pred = np.dot(weights.T,X) + Bias\n",
        "          prob_pred = sigmoid(score_pred)\n",
        "          y_pred = (prob_pred > 0.5).astype(int)\n",
        "          accuracy_list.append((1-np.sum(np.absolute(y_pred-Y))/Y.shape[1]))\n",
        "\n",
        "    return weights , Bias , accuracy_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB9XeCyKoAGy"
      },
      "outputs": [],
      "source": [
        "## Train the model using the training dataset.\n",
        "iterations = 1000\n",
        "learning_rate = 0.1\n",
        "weight , bias , accuracy_list_binary= BinaryLogisticRegression(X_train,Y_train,learning_rate,iterations,accuracy_track=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY8zh-epoABX",
        "outputId": "0e191bc7-ca9c-4899-c5d2-f011aadb2e3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy is :  0.7529076078528673\n"
          ]
        }
      ],
      "source": [
        "## Evaluate the model's performance on the training set by computing accuracy.\n",
        "\n",
        "score_pred = np.dot(weight.T,X_train) + bias\n",
        "prob_pred = sigmoid(score_pred)\n",
        "prob_pred[prob_pred > 0.5] = np.float64(1)\n",
        "prob_pred[prob_pred <= 0.5] = np.float64(0)\n",
        "print(\"Training accuracy is : \" ,(1-np.sum(np.absolute(prob_pred-Y_train))/Y_train.shape[1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AUPSGkss_xx"
      },
      "source": [
        "### 2.5. Model Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujz4g2mJs_xx",
        "outputId": "2d768965-5acb-468c-f0e0-e906eab4a96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy is :  0.7574742587768267\n"
          ]
        }
      ],
      "source": [
        "## Make predictions on the test set using the trained model.\n",
        "## Calculate accuracy for the test set.\n",
        "## Comment on the scores.\n",
        "\n",
        "score_pred = np.dot(weight.T,X_test) + bias\n",
        "prob_pred = sigmoid(score_pred)\n",
        "y_pred = (prob_pred > 0.5).astype(int)\n",
        "print(\"Test accuracy is : \" ,(1-np.sum(np.absolute(y_pred-Y_test))/Y_test.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gok7dpeRfFE"
      },
      "source": [
        "* I do not expect that I will get lower accuracy in the binary classification than multiclass one in begining of the assignment but when I ask it from piazza I learn that it is in good range of accuracy. I think it cause because of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekB08ld8rjRw"
      },
      "outputs": [],
      "source": [
        "def CalculateAccuracy1(df2,SamplingParameter,ScalingParameter,SelectionParameter):\n",
        "  X_train,X_test,Y_train,Y_test = DfToTrainAndSplit(df2,SamplingParameter,ScalingParameter,SelectionParameter)\n",
        "  weight, bias, _ = BinaryLogisticRegression(X_train, Y_train, 0.1, 1000)\n",
        "\n",
        "  score_pred = np.dot(weight.T,X_test) + bias\n",
        "  prob_pred = sigmoid(score_pred)\n",
        "  y_pred = (prob_pred > 0.5).astype(int)\n",
        "  accuracy = (1-np.sum(np.absolute(y_pred-Y_test))/Y_test.shape[1])\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6t-ZpqGnwuH"
      },
      "outputs": [],
      "source": [
        "## Create a table to present the test accuracy for different feature scaling and selection methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC6pfN_kKXTt"
      },
      "source": [
        "For the 3 table creating cell above this markdown will be run approximately 1.5 minutes because I train the model more than one times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdVOt3X0wBDq",
        "outputId": "1161981d-5b1c-45da-b8b6-ddaba54280e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+---------------+--------------------+\n",
            "| Number of Iterations | Learning Rate |      Accuracy      |\n",
            "+----------------------+---------------+--------------------+\n",
            "|         5000         |     0.001     | 0.7533184468428235 |\n",
            "|         2000         |     0.001     | 0.7547450688500186 |\n",
            "|         1000         |     0.001     | 0.7560476367696316 |\n",
            "|         5000         |      0.01     | 0.758342637389902  |\n",
            "|         2000         |      0.01     | 0.7571020965140801 |\n",
            "|         1000         |      0.01     | 0.7551172311127652 |\n",
            "|         5000         |      0.1      | 0.754310879543481  |\n",
            "|         2000         |      0.1      | 0.7562337179010048 |\n",
            "|         1000         |      0.1      | 0.7536906091055701 |\n",
            "+----------------------+---------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# train the model with training dataset in different learning rates and iterations, calculate accuracy and append list to calculate the comparison table\n",
        "myTable_1 = PrettyTable([\"Number of Iterations\", \"Learning Rate\",\"Accuracy\"])\n",
        "\n",
        "learning_rate_list = [0.001,0.01,0.1]\n",
        "num_iterations = [5000,2000,1000]\n",
        "for learningRate in learning_rate_list:\n",
        "  for Iteration in num_iterations:\n",
        "    myTable_1.add_row([Iteration, learningRate, CalculateAccuracy1(df,0,1,1)])\n",
        "\n",
        "print(myTable_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRMvjyzHSFr9"
      },
      "source": [
        "* We can see that effect of number of iterations and learning rate change is lower than multiclass one because the accuracy results are very similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxfxHv5-uN7Z",
        "outputId": "d2ef5747-be9c-4049-b69d-f4c70d740323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling and Scaling Methods Table\n",
            "+-----------------+------------------------+--------------------+\n",
            "| Sampling Method | Feature Scaling Method |      Accuracy      |\n",
            "+-----------------+------------------------+--------------------+\n",
            "|  Undersampling  |     Normalization      | 0.6736757226150601 |\n",
            "|   Oversampling  |     Normalization      | 0.6756949394155382 |\n",
            "|  Undersampling  |    Standardization     | 0.7589008807840218 |\n",
            "|   Oversampling  |    Standardization     | 0.7542567514057179 |\n",
            "+-----------------+------------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "## Create a table to present the test accuracy for different feature scaling and selection methods.\n",
        "myTable = PrettyTable([\"Sampling Method\", \"Feature Scaling Method\",\"Accuracy\"])\n",
        "\n",
        "myTable.add_row([\"Undersampling\", \"Normalization\" , CalculateAccuracy1(df,0,0,1)])\n",
        "myTable.add_row([\"Oversampling\", \"Normalization\", CalculateAccuracy1(df,1,0,1)])\n",
        "myTable.add_row([\"Undersampling\", \"Standardization\" , CalculateAccuracy1(df,0,1,1)])\n",
        "myTable.add_row([\"Oversampling\", \"Standardization\", CalculateAccuracy1(df,1,1,1)])\n",
        "\n",
        "print(\"Sampling and Scaling Methods Table\")\n",
        "print(myTable)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIOxZ1FgSSEo"
      },
      "source": [
        "* We can see that in this dataset main game changer is the feature scaling method change. Because the effect of sampling method and feature selecting method effect (table is in the above cell) very smaller compare to scaling. If we want to take the best accuracy we have to make feature scaling method as standardization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j24IaXFAvq_N",
        "outputId": "a5df57f4-6a90-4f20-8823-d1e74ed3a0e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Selection Methods and Accuracy Table\n",
            "+--------------------------+--------------------+\n",
            "| Feature Selection Method |      Accuracy      |\n",
            "+--------------------------+--------------------+\n",
            "|       Correlation        | 0.6478973627940128 |\n",
            "|     Chi-Square Test      | 0.6756553417280431 |\n",
            "+--------------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# Table to see the difference between feature selection methods' effect on accuracy\n",
        "myTable = PrettyTable([\"Feature Selection Method\",\"Accuracy\"])\n",
        "\n",
        "myTable.add_row([\"Correlation\", CalculateAccuracy1(df,1,0,0)])\n",
        "myTable.add_row([\"Chi-Square Test\", CalculateAccuracy1(df,1,0,1)])\n",
        "\n",
        "print(\"Feature Selection Methods and Accuracy Table\")\n",
        "print(myTable)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qQKMOXHSo7C"
      },
      "source": [
        "* Very small difference between the selection methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biAtQZdWs_xy"
      },
      "source": [
        "### 2.6 Results Analysis and Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DYImwx7s_xy"
      },
      "outputs": [],
      "source": [
        "## Plot training accuracys to visualize the learning curve.\n",
        "## Interpret the results of the ablation study on feature scaling and selection.\n",
        "## Discuss the impact of feature scaling on model performance.\n",
        "## Summarize key findings from the logistic regression analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU3KznT4UPMS"
      },
      "source": [
        "* For first three task I did them in the previous cells.\n",
        "\n",
        "* For the last summarizing one:\n",
        "  For this type of dataset logistic regression works best when we choose feature scaling method standardazing and feature selection method Chi-Square Test. Accuracy is not bad for this type of dataset. Also I want to add that when we make correlation it runs faster than the chi-square one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "31qCiBvXCVWM",
        "outputId": "2b0f2635-d076-4f9a-b9b6-e913bcae3a4e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "index_list = []\n",
        "for i in range(len(accuracy_list_binary)):\n",
        "    index_list.append(i)\n",
        "\n",
        "plt.title(\"Training Learning Curve\")\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(index_list,accuracy_list_binary, color=\"black\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFiFfV-SSt5P"
      },
      "source": [
        "* Just like in multiclass graph this small decrase in accuracy parts are there because of the learning rate is higher than it have to be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CibWQBnMDXV9"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Thank you for reading my code and report. I hope you like my Assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjU40Q8TDXqq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
